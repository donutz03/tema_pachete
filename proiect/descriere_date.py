import streamlit as st
import pandas as pd
import numpy as np
import geopandas as gpd
import plotly.express as px
import seaborn as sns
import matplotlib.pyplot as plt
from datetime import datetime
from sklearn.impute import KNNImputer
from scipy import stats
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import statsmodels.api as sm
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, calinski_harabasz_score
from scalare_utils import aplica_scalare, adauga_sectiune_scalare

st.set_page_config(page_title="US Accidents Analysis", layout="wide")

with st.expander("游늶 Dataset Description"):
    st.markdown("""
    ### Data Dictionary

    This dataset contains information about traffic accidents across the United States between 2016 and 2023. Here's what each column represents:

    #### Identification
    - **ID**: Unique identifier of the accident record
    - **Source**: Source of raw accident data

    #### Accident Details
    - **Severity**: Severity of the accident (1-4), where 1 indicates least impact on traffic (short delay) and 4 indicates significant impact (long delay)
    - **Start_Time**: Start time of the accident in local time zone
    - **End_Time**: When the impact of accident on traffic flow was dismissed
    - **Distance(mi)**: Length of the road affected by the accident in miles
    - **Description**: Human-provided description of the accident

    #### Location Information
    - **Start_Lat/Start_Lng**: GPS coordinates of the start point
    - **End_Lat/End_Lng**: GPS coordinates of the end point
    - **Street**: Street name
    - **City**: City name
    - **County**: County name
    - **State**: State abbreviation
    - **Zipcode**: ZIP code
    - **Country**: Country (US)
    - **Timezone**: Timezone based on location (eastern, central, etc.)

    #### Weather Conditions
    - **Airport_Code**: Closest airport-based weather station
    - **Weather_Timestamp**: Time of weather observation
    - **Temperature(F)**: Temperature in Fahrenheit
    - **Wind_Chill(F)**: Wind chill in Fahrenheit
    - **Humidity(%)**: Humidity percentage
    - **Pressure(in)**: Air pressure in inches
    - **Visibility(mi)**: Visibility in miles
    - **Wind_Direction**: Wind direction
    - **Wind_Speed(mph)**: Wind speed in mph
    - **Precipitation(in)**: Precipitation amount in inches
    - **Weather_Condition**: Weather condition (rain, snow, etc.)

    #### Point of Interest (POI) Annotations
    These boolean fields indicate presence of various features near the accident:
    - **Amenity**, **Bump**, **Crossing**, **Give_Way**, **Junction**, **No_Exit**
    - **Railway**, **Roundabout**, **Station**, **Stop**
    - **Traffic_Calming**, **Traffic_Signal**, **Turning_Loop**

    #### Time of Day Indicators
    - **Sunrise_Sunset**: Day or night based on sunrise/sunset
    - **Civil_Twilight**: Day or night based on civil twilight
    - **Nautical_Twilight**: Day or night based on nautical twilight
    - **Astronomical_Twilight**: Day or night based on astronomical twilight
    """)

#old load data, cu toate datele
@st.cache_data
def load_data():
    df = pd.read_csv('US_Accidents_Sample_1000_Per_Year.csv')

    df['Start_Time'] = pd.to_datetime(df['Start_Time'], format='mixed')
    df['End_Time'] = pd.to_datetime(df['End_Time'], format='mixed')

    df['Duration'] = (df['End_Time'] - df['Start_Time']).dt.total_seconds() / 60

    return df

st.title("游늵 Analiza Exploratorie a Accidentelor Rutiere")

with st.sidebar:
    st.header("Meniu Principal")
    menu = st.radio(
        "Selecteaz캒 sec탵iunea:",
        ["Analiz캒 General캒", "Tratarea Valorilor Lips캒", "Identificarea Valorilor Extreme", "Grup캒ri 탳i Corela탵ii",
         "Scalarea Datelor", "Codificare 탳i Regresie", "Clusterizare"]
    )

    st.header("Filtrare Date")
    selected_years = st.slider("Selecteaz캒 Anii",
                               min_value=2016,
                               max_value=2023,
                               value=(2023, 2023))

    st.markdown("---")
    st.markdown("### Alte filtre")
    severity_levels = st.multiselect("Niveluri de Severitate",
                                     options=[1, 2, 3, 4],
                                     default=[1, 2, 3, 4])

df = load_data()

filtered_df = df[
    (df['Start_Time'].dt.year >= selected_years[0]) &
    (df['Start_Time'].dt.year <= selected_years[1]) &
    (df['Severity'].isin(severity_levels))
    ]

if menu == "Analiz캒 General캒":
    st.header("游늵 Informa탵ii despre setul de date")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Num캒r de accidente", f"{filtered_df.shape[0]:,}")
    with col2:
        st.metric("Num캒r de coloane", f"{filtered_df.shape[1]}")
    with col3:
        st.metric("Perioada acoperit캒",
                  f"{filtered_df['Start_Time'].dt.year.min()} - {filtered_df['Start_Time'].dt.year.max()}")

    st.subheader("Primele 칥nregistr캒ri")
    st.dataframe(filtered_df.head(10), use_container_width=True)

    st.subheader("Informa탵ii despre tipurile de date")
    data_types = pd.DataFrame({
        'Coloan캒': filtered_df.dtypes.index,
        'Tip': filtered_df.dtypes.values,
        'Valori Nule': filtered_df.isna().sum().values,
        'Procent Nule': (filtered_df.isna().sum().values / len(filtered_df) * 100).round(2)
    })
    st.dataframe(data_types, use_container_width=True)

    st.subheader("Statistici de baz캒")
    st.dataframe(filtered_df.describe(), use_container_width=True)

elif menu == "Tratarea Valorilor Lips캒":
    st.header("游빌 Tratarea Valorilor Lips캒")

    na_cols = filtered_df.columns[filtered_df.isna().any()].tolist()

    if not na_cols:
        st.info("Nu exist캒 valori lips캒 칥n datele filtrate!")
    else:
        selected_col = st.selectbox("Selecteaz캒 coloana pentru tratarea valorilor lips캒", na_cols)

        st.subheader(f"Vizualizarea valorilor lips캒 pentru coloana {selected_col}")

        col1, col2 = st.columns(2)
        with col1:
            st.metric("Total valori lips캒", filtered_df[selected_col].isna().sum())
            st.metric("Procent valori lips캒",
                      f"{(filtered_df[selected_col].isna().sum() / len(filtered_df) * 100):.2f}%")

        with col2:
            if pd.api.types.is_numeric_dtype(filtered_df[selected_col]):
                fig, ax = plt.subplots(figsize=(6, 3))
                filtered_df[selected_col].hist(ax=ax)
                st.pyplot(fig)

        st.subheader("Metode de tratare a valorilor lips캒")

        tabs = st.tabs(
            ["Metoda 1: 칉nlocuire cu media/mediana/mod", "Metoda 2: 칉nlocuire cu KNN", "Metoda 3: Interpolare"])

        with tabs[0]:
            st.markdown("#### 칉nlocuire cu statistici")

            if pd.api.types.is_numeric_dtype(filtered_df[selected_col]):
                method = st.radio("Alege metoda de 칥nlocuire:", ["Media", "Mediana"])

                if method == "Media":
                    replace_value = filtered_df[selected_col].mean()
                    df_replaced = filtered_df.copy()
                    df_replaced[selected_col] = df_replaced[selected_col].fillna(replace_value)

                    st.success(f"Valorile lips캒 au fost 칥nlocuite cu media: {replace_value:.2f}")

                elif method == "Mediana":
                    replace_value = filtered_df[selected_col].median()
                    df_replaced = filtered_df.copy()
                    df_replaced[selected_col] = df_replaced[selected_col].fillna(replace_value)

                    st.success(f"Valorile lips캒 au fost 칥nlocuite cu mediana: {replace_value:.2f}")

                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("##### 칉nainte de 칥nlocuire")
                    st.dataframe(filtered_df[[selected_col]].describe(), use_container_width=True)

                with col2:
                    st.markdown("##### Dup캒 칥nlocuire")
                    st.dataframe(df_replaced[[selected_col]].describe(), use_container_width=True)

            else:
                mode_value = filtered_df[selected_col].mode()[0]
                df_replaced = filtered_df.copy()
                df_replaced[selected_col] = df_replaced[selected_col].fillna(mode_value)

                st.success(f"Pentru coloana categoric캒, valorile lips캒 au fost 칥nlocuite cu modul: {mode_value}")

        with tabs[1]:
            st.markdown("#### 칉nlocuire cu KNN")

            if pd.api.types.is_numeric_dtype(filtered_df[selected_col]):
                k_neighbors = st.slider("Num캒r de vecini (K)", 1, 10, 5)

                numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()

                # Select캒m doar c칙teva coloane numerice pentru demonstra탵ie
                cols_for_imputation = st.multiselect(
                    "Selecteaz캒 coloanele pentru imputare (se recomand캒 coloane corelate)",
                    numeric_cols,
                    default=[selected_col] + [c for c in numeric_cols if c != selected_col][:2]
                )

                if len(cols_for_imputation) > 1:
                    imputer = KNNImputer(n_neighbors=k_neighbors)

                    # Extragem doar coloanele relevante 탳i elimin캒m r칙ndurile unde toate valorile sunt NA
                    subset_df = filtered_df[cols_for_imputation].copy()
                    subset_df = subset_df.dropna(how='all')

                    # Aplic캒m imputarea
                    imputed_array = imputer.fit_transform(subset_df)
                    imputed_df = pd.DataFrame(imputed_array, columns=cols_for_imputation)

                    st.success(f"Valorile lips캒 au fost 칥nlocuite folosind metoda KNN cu {k_neighbors} vecini")

                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("##### 칉nainte de 칥nlocuire")
                        st.dataframe(filtered_df[selected_col].describe(), use_container_width=True)

                    with col2:
                        st.markdown("##### Dup캒 칥nlocuire")
                        st.dataframe(imputed_df[selected_col].describe(), use_container_width=True)
                else:
                    st.warning("Selecta탵i cel pu탵in 2 coloane pentru imputare KNN")
            else:
                st.warning("Metoda KNN este aplicabil캒 doar pentru coloane numerice")

        with tabs[2]:
            st.markdown("#### Interpolare")

            if pd.api.types.is_numeric_dtype(filtered_df[selected_col]):
                method = st.radio("Metoda de interpolare:", ["Linear", "Polynomial", "Spline"])

                df_interpolated = filtered_df.copy()

                if method == "Linear":
                    df_interpolated[selected_col] = df_interpolated[selected_col].interpolate(method='linear')
                    st.success("Interpolare liniar캒 aplicat캒")

                elif method == "Polynomial":
                    df_interpolated[selected_col] = df_interpolated[selected_col].interpolate(method='polynomial',
                                                                                              order=2)
                    st.success("Interpolare polinomial캒 de gradul 2 aplicat캒")

                elif method == "Spline":
                    df_interpolated[selected_col] = df_interpolated[selected_col].interpolate(method='spline', order=3)
                    st.success("Interpolare spline cubic캒 aplicat캒")

                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("##### 칉nainte de interpolare")
                    st.dataframe(filtered_df[[selected_col]].head(20), use_container_width=True)

                with col2:
                    st.markdown("##### Dup캒 interpolare")
                    st.dataframe(df_interpolated[[selected_col]].head(20), use_container_width=True)

                st.markdown("##### Compara탵ie statistici")
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("칉nainte")
                    st.dataframe(filtered_df[selected_col].describe(), use_container_width=True)

                with col2:
                    st.markdown("Dup캒")
                    st.dataframe(df_interpolated[selected_col].describe(), use_container_width=True)
            else:
                st.warning("Interpolarea este aplicabil캒 doar pentru coloane numerice")

elif menu == "Identificarea Valorilor Extreme":
    st.header("游댌 Identificarea 탳i Tratarea Valorilor Extreme")

    numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()

    col_for_outlier = st.selectbox("Selecteaz캒 coloana pentru analiza outlierilor", numeric_cols)

    st.subheader(f"Analiz캒 outlieri pentru {col_for_outlier}")

    col1, col2 = st.columns([1, 2])

    with col1:
        st.markdown("### Statistici")
        # Calculeaz캒 outlieri folosind IQR
        Q1 = filtered_df[col_for_outlier].quantile(0.25)
        Q3 = filtered_df[col_for_outlier].quantile(0.75)
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        outliers = \
        filtered_df[(filtered_df[col_for_outlier] < lower_bound) | (filtered_df[col_for_outlier] > upper_bound)][
            col_for_outlier]

        st.metric("Num캒r de outlieri", outliers.count())
        st.metric("Procent outlieri", f"{(outliers.count() / filtered_df[col_for_outlier].count() * 100):.2f}%")
        st.metric("Limita inferioar캒", f"{lower_bound:.2f}")
        st.metric("Limita superioar캒", f"{upper_bound:.2f}")

        if outliers.count() > 0:
            st.metric("Minim outlieri", f"{outliers.min():.2f}")
            st.metric("Maxim outlieri", f"{outliers.max():.2f}")

    with col2:
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.boxplot(x=filtered_df[col_for_outlier], ax=ax)
        ax.set_title(f"Boxplot pentru {col_for_outlier}")
        st.pyplot(fig)

        # Histogram캒 cu distribu탵ie
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.histplot(filtered_df[col_for_outlier], kde=True, ax=ax)
        ax.axvline(lower_bound, color='r', linestyle='--')
        ax.axvline(upper_bound, color='r', linestyle='--')
        ax.set_title(f"Histogram캒 cu limite outlieri pentru {col_for_outlier}")
        st.pyplot(fig)

    st.subheader("Metode de tratare a outlierilor")

    outlier_method = st.radio(
        "Selecteaz캒 metoda de tratare:",
        ["Vizualizare f캒r캒 tratare", "칉nlocuire cu limite", "Transformare logaritmic캒", "칉nlocuire cu valori calculate"]
    )

    if outlier_method == "Vizualizare f캒r캒 tratare":
        st.dataframe(filtered_df[[col_for_outlier]].describe(), use_container_width=True)

        # Prezint캒 top 10 valori extreme
        if outliers.count() > 0:
            st.subheader("Top 10 valori extreme")
            extreme_values = outliers.sort_values(ascending=False).head(10)
            st.dataframe(pd.DataFrame(extreme_values), use_container_width=True)

    elif outlier_method == "칉nlocuire cu limite":
        df_capped = filtered_df.copy()

        df_capped[col_for_outlier] = df_capped[col_for_outlier].clip(lower=lower_bound, upper=upper_bound)

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### 칉nainte de tratare")
            st.dataframe(filtered_df[col_for_outlier].describe(), use_container_width=True)

            fig, ax = plt.subplots(figsize=(8, 4))
            sns.boxplot(x=filtered_df[col_for_outlier], ax=ax)
            st.pyplot(fig)

        with col2:
            st.markdown("##### Dup캒 칥nlocuire cu limite")
            st.dataframe(df_capped[col_for_outlier].describe(), use_container_width=True)

            fig, ax = plt.subplots(figsize=(8, 4))
            sns.boxplot(x=df_capped[col_for_outlier], ax=ax)
            st.pyplot(fig)

    elif outlier_method == "Transformare logaritmic캒":
        if (filtered_df[col_for_outlier] <= 0).any():
            st.warning(
                "Transformarea logaritmic캒 necesit캒 valori pozitive. Ad캒ug캒m o constant캒 pentru a face toate valorile pozitive.")
            min_val = filtered_df[col_for_outlier].min()
            constant = abs(min_val) + 1 if min_val <= 0 else 0

            df_log = filtered_df.copy()
            df_log[col_for_outlier] = np.log(df_log[col_for_outlier] + constant)

            st.success(
                f"Am ad캒ugat constanta {constant} pentru a face toate valorile pozitive 칥nainte de transformarea log")
        else:
            df_log = filtered_df.copy()
            df_log[col_for_outlier] = np.log(df_log[col_for_outlier])

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### Distribu탵ia original캒")
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.histplot(filtered_df[col_for_outlier], kde=True, ax=ax)
            st.pyplot(fig)

        with col2:
            st.markdown("##### Distribu탵ia dup캒 transformarea log")
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.histplot(df_log[col_for_outlier], kde=True, ax=ax)
            st.pyplot(fig)

        st.dataframe(df_log[col_for_outlier].describe(), use_container_width=True)

    elif outlier_method == "칉nlocuire cu valori calculate":
        replace_method = st.radio(
            "Metod캒 de 칥nlocuire:",
            ["Medie", "Median캒", "Calcul bazat pe percentile"]
        )

        df_replaced = filtered_df.copy()

        if replace_method == "Medie":
            # Excludem outlieri din calculul mediei
            mean_no_outliers = filtered_df[(filtered_df[col_for_outlier] >= lower_bound) &
                                           (filtered_df[col_for_outlier] <= upper_bound)][col_for_outlier].mean()

            # 칉nlocuim doar outlieri
            df_replaced.loc[(df_replaced[col_for_outlier] < lower_bound), col_for_outlier] = mean_no_outliers
            df_replaced.loc[(df_replaced[col_for_outlier] > upper_bound), col_for_outlier] = mean_no_outliers

            st.success(f"Outlieri 칥nlocui탵i cu media f캒r캒 outlieri: {mean_no_outliers:.2f}")

        elif replace_method == "Median캒":
            median = filtered_df[col_for_outlier].median()

            df_replaced.loc[(df_replaced[col_for_outlier] < lower_bound), col_for_outlier] = median
            df_replaced.loc[(df_replaced[col_for_outlier] > upper_bound), col_for_outlier] = median

            st.success(f"Outlieri 칥nlocui탵i cu mediana: {median:.2f}")

        elif replace_method == "Calcul bazat pe percentile":
            p10 = filtered_df[col_for_outlier].quantile(0.10)
            p90 = filtered_df[col_for_outlier].quantile(0.90)

            df_replaced.loc[(df_replaced[col_for_outlier] < lower_bound), col_for_outlier] = p10
            df_replaced.loc[(df_replaced[col_for_outlier] > upper_bound), col_for_outlier] = p90

            st.success(f"Outlieri mici 칥nlocui탵i cu percentila 10: {p10:.2f}")
            st.success(f"Outlieri mari 칥nlocui탵i cu percentila 90: {p90:.2f}")

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### Boxplot 칥nainte de 칥nlocuire")
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.boxplot(x=filtered_df[col_for_outlier], ax=ax)
            st.pyplot(fig)

        with col2:
            st.markdown("##### Boxplot dup캒 칥nlocuire")
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.boxplot(x=df_replaced[col_for_outlier], ax=ax)
            st.pyplot(fig)

        st.subheader("Compara탵ie statistici")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### 칉nainte")
            st.dataframe(filtered_df[col_for_outlier].describe(), use_container_width=True)

        with col2:
            st.markdown("##### Dup캒")
            st.dataframe(df_replaced[col_for_outlier].describe(), use_container_width=True)

elif menu == "Grup캒ri 탳i Corela탵ii":
    st.header("游늵 Grup캒ri 탳i Corela탵ii")

    tabs = st.tabs(["Corela탵ii", "Grup캒ri", "Func탵ii Agregate"])

    with tabs[0]:
        st.subheader("Matricea de corela탵ie")

        numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()
        selected_cols = st.multiselect(
            "Selecteaz캒 coloanele pentru analiza corela탵iilor",
            numeric_cols,
            default=numeric_cols[:8]  # Primele 8 coloane numerice
        )

        if not selected_cols:
            st.warning("Selecta탵i cel pu탵in o coloan캒!")
        else:
            corr_method = st.radio("Metoda de corela탵ie:", ["Pearson", "Spearman", "Kendall"])

            fig, ax = plt.subplots(figsize=(12, 10))
            corr_matrix = filtered_df[selected_cols].corr(method=corr_method.lower())

            mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
            sns.heatmap(corr_matrix, mask=mask, annot=True, fmt=".2f",
                        cmap="coolwarm", ax=ax, cbar_kws={"shrink": .8})

            plt.title(f"Matrice de corela탵ie folosind metoda {corr_method}")
            plt.tight_layout()
            st.pyplot(fig)

            st.subheader("Selecteaz캒 perechi de coloane pentru analiz캒")

            col1, col2 = st.columns(2)
            with col1:
                x_col = st.selectbox("Coloana X", selected_cols, index=0)
            with col2:
                y_col = st.selectbox("Coloana Y", [c for c in selected_cols if c != x_col], index=0)

            fig, ax = plt.subplots(figsize=(10, 6))
            sns.regplot(x=filtered_df[x_col], y=filtered_df[y_col], ax=ax)
            plt.title(f"Rela탵ia dintre {x_col} 탳i {y_col}")
            plt.tight_layout()
            st.pyplot(fig)

            st.metric(f"Coeficient de corela탵ie {corr_method}",
                      f"{filtered_df[x_col].corr(filtered_df[y_col], method=corr_method.lower()):.3f}")

    with tabs[1]:
        st.subheader("Gruparea datelor")

        # Coloane pentru grupare
        all_cols = filtered_df.columns.tolist()
        categorical_cols = filtered_df.select_dtypes(include=['object', 'category']).columns.tolist()
        date_cols = ['Start_Time']

        # Ad캒ug캒m coloane derivate pentru grupare temporal캒
        filtered_df['Month'] = filtered_df['Start_Time'].dt.month
        filtered_df['DayOfWeek'] = filtered_df['Start_Time'].dt.dayofweek
        filtered_df['Hour'] = filtered_df['Start_Time'].dt.hour

        group_by_options = categorical_cols + ['Month', 'DayOfWeek', 'Hour', 'Severity']

        col1, col2 = st.columns(2)
        with col1:
            groupby_col = st.selectbox("Grupeaz캒 dup캒", group_by_options)

        with col2:
            agg_col = st.selectbox("Aplic캒 func탵ie pe coloana",
                                   [c for c in filtered_df.select_dtypes(include=[np.number]).columns if
                                    c != groupby_col])

        agg_func = st.radio("Func탵ie de agregare", ["Num캒r", "Medie", "Sum캒", "Minim", "Maxim", "Median캒"])

        if agg_func == "Num캒r":
            result_df = filtered_df.groupby(groupby_col).size().reset_index(name='Num캒r')
        elif agg_func == "Medie":
            result_df = filtered_df.groupby(groupby_col)[agg_col].mean().reset_index(name=f'Medie {agg_col}')
        elif agg_func == "Sum캒":
            result_df = filtered_df.groupby(groupby_col)[agg_col].sum().reset_index(name=f'Sum캒 {agg_col}')
        elif agg_func == "Minim":
            result_df = filtered_df.groupby(groupby_col)[agg_col].min().reset_index(name=f'Minim {agg_col}')
        elif agg_func == "Maxim":
            result_df = filtered_df.groupby(groupby_col)[agg_col].max().reset_index(name=f'Maxim {agg_col}')
        elif agg_func == "Median캒":
            result_df = filtered_df.groupby(groupby_col)[agg_col].median().reset_index(name=f'Median캒 {agg_col}')

        # Sort캒m rezultatul
        if agg_func == "Num캒r":
            result_df = result_df.sort_values(by='Num캒r', ascending=False)
        else:
            result_df = result_df.sort_values(by=result_df.columns[1], ascending=False)

        st.subheader("Rezultat grupare")
        st.dataframe(result_df, use_container_width=True)

        # Vizualiz캒m rezultatul cu un grafic
        fig = px.bar(
            result_df.head(20),
            x=groupby_col,
            y=result_df.columns[1],
            title=f"{agg_func} de {agg_col if agg_func != 'Num캒r' else 'accidente'} grupat dup캒 {groupby_col}"
        )
        fig.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig, use_container_width=True)

    with tabs[2]:
        st.subheader("Func탵ii de agregare multiple")

        all_cols = filtered_df.columns.tolist()
        categorical_cols = filtered_df.select_dtypes(include=['object', 'category']).columns.tolist()
        numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()

        col1, col2 = st.columns(2)
        with col1:
            groupby_cols = st.multiselect("Grupeaz캒 dup캒 (selecteaz캒 una sau mai multe coloane)",
                                          categorical_cols + ['Month', 'DayOfWeek', 'Hour', 'Severity'],
                                          default=[categorical_cols[0] if categorical_cols else 'Severity'])

        with col2:
            agg_cols = st.multiselect("Coloane pentru agregare",
                                      [c for c in numeric_cols if c not in groupby_cols],
                                      default=[numeric_cols[0] if numeric_cols else 'Duration'])

        agg_funcs = st.multiselect("Func탵ii de agregare",
                                   ["count", "mean", "sum", "min", "max", "median", "std", "var"],
                                   default=["count", "mean"])

        if not groupby_cols:
            st.warning("Selecta탵i cel pu탵in o coloan캒 pentru grupare!")
        elif not agg_cols:
            st.warning("Selecta탵i cel pu탵in o coloan캒 pentru agregare!")
        elif not agg_funcs:
            st.warning("Selecta탵i cel pu탵in o func탵ie de agregare!")
        else:
            # Construim dic탵ionarul pentru agregare
            agg_dict = {col: agg_funcs for col in agg_cols}

            result_df = filtered_df.groupby(groupby_cols).agg(agg_dict)

            # Reset캒m index-ul pentru afi탳are mai u탳oar캒
            result_df = result_df.reset_index()

            # Afi탳캒m rezultatul
            st.dataframe(result_df, use_container_width=True)

            # Op탵iune pentru desc캒rcare
            csv = result_df.to_csv(index=False)
            st.download_button(
                label="Descarc캒 rezultatele 칥n CSV",
                data=csv,
                file_name=f"grupare_{'_'.join(groupby_cols)}.csv",
                mime="text/csv"
            )

            # Vizualizare grafic캒 pentru prima func탵ie de agregare 탳i prima coloan캒
            if len(groupby_cols) == 1 and len(result_df) <= 25:
                agg_col_name = f"{agg_cols[0]}_{agg_funcs[0]}"

                fig = px.bar(
                    result_df.head(25),
                    x=groupby_cols[0],
                    y=agg_col_name,
                    title=f"{agg_funcs[0]} de {agg_cols[0]} grupat dup캒 {groupby_cols[0]}"
                )
                fig.update_layout(xaxis_tickangle=-45)
                st.plotly_chart(fig, use_container_width=True)

elif menu == "Scalarea Datelor":
    # Aplic캒m func탵ia pentru vizualizarea 탳i aplicarea metodelor de scalare
    st.header("游댃 Metode de Scalare a Datelor")
    adauga_sectiune_scalare(filtered_df, sidebar=False)

# Ad캒ug캒m o nou캒 op탵iune pentru BoxPlot interactiv
st.sidebar.markdown("---")
if st.sidebar.checkbox("Activeaz캒 BoxPlot Interactiv"):
    st.header("游늵 BoxPlot Interactiv")

    numeric_columns = filtered_df.select_dtypes(include=[np.number]).columns.tolist()
    selected_column = st.selectbox("Selecteaz캒 coloana pentru BoxPlot", numeric_columns)

    col1, col2 = st.columns([2, 1])

    with col1:
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.boxplot(y=filtered_df[selected_column], ax=ax)
        ax.set_title(f"BoxPlot pentru {selected_column}")
        st.pyplot(fig)

    with col2:
        st.markdown("### Statistici")
        stats = filtered_df[selected_column].describe()

        # Calcul캒m manual IQR pentru limite de outlieri
        Q1 = stats["25%"]
        Q3 = stats["75%"]
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        outliers_count = filtered_df[(filtered_df[selected_column] < lower_bound) |
                                     (filtered_df[selected_column] > upper_bound)].shape[0]

        st.metric("Minim", f"{stats['min']:.2f}")
        st.metric("Q1 (25%)", f"{Q1:.2f}")
        st.metric("Median캒", f"{stats['50%']:.2f}")
        st.metric("Q3 (75%)", f"{Q3:.2f}")
        st.metric("Maxim", f"{stats['max']:.2f}")
        st.metric("IQR", f"{IQR:.2f}")
        st.metric("Limita inferioar캒", f"{lower_bound:.2f}")
        st.metric("Limita superioar캒", f"{upper_bound:.2f}")
        st.metric("Num캒r outlieri", f"{outliers_count} ({outliers_count / len(filtered_df) * 100:.1f}%)")

    if st.checkbox("Arat캒 histograma"):
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.histplot(filtered_df[selected_column], kde=True, ax=ax)
        plt.axvline(lower_bound, color='r', linestyle='--', label='Limite outlieri')
        plt.axvline(upper_bound, color='r', linestyle='--')
        plt.legend()
        st.pyplot(fig)

elif menu == "Codificare 탳i Regresie":
    st.header("游댝 Codificare 탳i Analiz캒 de Regresie")
    
    tabs = st.tabs(["Codificare Date", "Regresie Logistic캒", "Regresie Multipl캒"])
    
    with tabs[0]:
        st.subheader("Codificare Date")
        
        # Select캒m coloanele categorice pentru codificare
        categorical_cols = filtered_df.select_dtypes(include=['object']).columns.tolist()
        selected_col = st.selectbox("Selecteaz캒 coloana pentru codificare", categorical_cols)
        
        encoding_method = st.radio("Alege metoda de codificare:", ["Label Encoding", "One-Hot Encoding"])
        
        if encoding_method == "Label Encoding":
            le = LabelEncoder()
            encoded_values = le.fit_transform(filtered_df[selected_col].fillna('Missing'))
            
            # Cre캒m un DataFrame pentru vizualizare
            encoding_df = pd.DataFrame({
                'Valoare Original캒': filtered_df[selected_col].fillna('Missing'),
                'Valoare Codificat캒': encoded_values
            }).drop_duplicates().sort_values('Valoare Codificat캒')
            
            st.dataframe(encoding_df, use_container_width=True)
            
        else:  # One-Hot Encoding
            ohe = OneHotEncoder(sparse=False)
            encoded_values = ohe.fit_transform(filtered_df[[selected_col]].fillna('Missing'))
            
            # Cre캒m un DataFrame pentru vizualizare
            feature_names = [f"{selected_col}_{val}" for val in ohe.categories_[0]]
            encoding_df = pd.DataFrame(encoded_values, columns=feature_names)
            
            st.dataframe(encoding_df.head(), use_container_width=True)
            
            # Vizualiz캒m distribu탵ia valorilor codificate
            fig = px.bar(encoding_df.sum(), title=f"Distribu탵ia valorilor codificate pentru {selected_col}")
            st.plotly_chart(fig)
    
    with tabs[1]:
        st.subheader("Regresie Logistic캒")
        
        # Select캒m variabilele pentru regresie logistic캒
        target_col = st.selectbox("Selecteaz캒 variabila 탵int캒 (binar캒)", 
                                ['Severity', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit'],
                                key="logistic_target")
        
        feature_cols = st.multiselect("Selecteaz캒 variabilele predictoare (numerice)",
                                    filtered_df.select_dtypes(include=[np.number]).columns.tolist(),
                                    default=['Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)'],
                                    key="logistic_features")
        
        if len(feature_cols) > 0:
            # Preg캒tim datele
            X = filtered_df[feature_cols].fillna(filtered_df[feature_cols].mean())
            y = (filtered_df[target_col] > filtered_df[target_col].median()).astype(int)
            
            # 칉mp캒r탵im datele 칥n set de antrenare 탳i test
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            # Antren캒m modelul
            model = LogisticRegression(max_iter=1000)
            model.fit(X_train, y_train)
            
            # Evalu캒m modelul
            y_pred = model.predict(X_test)
            
            st.subheader("Rezultate Model")
            st.text(classification_report(y_test, y_pred))
            
            # Vizualiz캒m matricea de confuzie
            cm = confusion_matrix(y_test, y_pred)
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
            ax.set_xlabel('Predicted')
            ax.set_ylabel('Actual')
            st.pyplot(fig)
            
            # Afi탳캒m coeficien탵ii modelului
            coef_df = pd.DataFrame({
                'Feature': feature_cols,
                'Coefficient': model.coef_[0]
            })
            st.dataframe(coef_df.sort_values('Coefficient', ascending=False), use_container_width=True)
    
    with tabs[2]:
        st.subheader("Regresie Multipl캒")
        
        # Select캒m variabilele pentru regresie multipl캒
        target_col = st.selectbox("Selecteaz캒 variabila 탵int캒 (numeric캒)", 
                                ['Duration', 'Distance(mi)', 'Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)'],
                                key="multiple_target")
        
        feature_cols = st.multiselect("Selecteaz캒 variabilele predictoare (numerice)",
                                    filtered_df.select_dtypes(include=[np.number]).columns.tolist(),
                                    default=['Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)'],
                                    key="multiple_features")
        
        if len(feature_cols) > 0:
            # Preg캒tim datele
            X = filtered_df[feature_cols].fillna(filtered_df[feature_cols].mean())
            y = filtered_df[target_col].fillna(filtered_df[target_col].mean())
            
            # Ad캒ug캒m constanta pentru statsmodels
            X = sm.add_constant(X)
            
            # Antren캒m modelul
            model = sm.OLS(y, X).fit()
            
            # Afi탳캒m rezultatele
            st.subheader("Rezultate Model")
            st.text(model.summary())
            
            # Vizualiz캒m reziduurile
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.scatter(model.fittedvalues, model.resid)
            ax.axhline(y=0, color='r', linestyle='--')
            ax.set_xlabel('Valori Prezise')
            ax.set_ylabel('Reziduuri')
            st.pyplot(fig)
            
            # Vizualiz캒m coeficien탵ii
            coef_df = pd.DataFrame({
                'Feature': ['const'] + feature_cols,
                'Coefficient': model.params,
                'P-value': model.pvalues
            })
            st.dataframe(coef_df.sort_values('P-value'), use_container_width=True)

elif menu == "Clusterizare":
    st.header("游댌 Analiza Clusteriz캒rii")
    
    # Select캒m variabilele pentru clusterizare
    numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()
    feature_cols = st.multiselect(
        "Selecteaz캒 variabilele pentru clusterizare",
        numeric_cols,
        default=['Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)'],
        key="cluster_features"
    )
    
    if len(feature_cols) > 1:
        # Preg캒tim datele
        X = filtered_df[feature_cols].fillna(filtered_df[feature_cols].mean())
        
        # Scal캒m datele
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Determin캒m num캒rul optim de clustere
        max_clusters = min(10, len(filtered_df) - 1)
        
        # Calcul캒m metricile pentru diferite numere de clustere
        silhouette_scores = []
        inertia_scores = []
        calinski_scores = []
        
        for n_clusters in range(2, max_clusters + 1):
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            clusters = kmeans.fit_predict(X_scaled)
            
            # Calcul캒m scorurile
            silhouette_scores.append(silhouette_score(X_scaled, clusters))
            inertia_scores.append(kmeans.inertia_)
            calinski_scores.append(calinski_harabasz_score(X_scaled, clusters))
        
        # Cre캒m un DataFrame cu rezultatele
        results_df = pd.DataFrame({
            'Num캒r Clustere': range(2, max_clusters + 1),
            'Scor Siluet캒': silhouette_scores,
            'Iner탵ie': inertia_scores,
            'Scor Calinski-Harabasz': calinski_scores
        })
        
        # Afi탳캒m rezultatele
        st.subheader("Determinarea num캒rului optim de clustere")
        
        # Cre캒m un tab pentru fiecare metod캒
        tabs = st.tabs(["Scor Siluet캒", "Metoda Cotului", "Calinski-Harabasz"])
        
        with tabs[0]:
            st.write("Scorul de siluet캒 m캒soar캒 c칙t de bine sunt separate clusterele. Valori mai mari indic캒 o clusterizare mai bun캒.")
            fig = px.line(results_df, x='Num캒r Clustere', y='Scor Siluet캒',
                         title='Scor Siluet캒 vs Num캒r Clustere')
            st.plotly_chart(fig, use_container_width=True)
            
            # G캒sim num캒rul optim de clustere bazat pe scorul de siluet캒
            optimal_silhouette = results_df.loc[results_df['Scor Siluet캒'].idxmax()]
            st.success(f"Num캒rul optim de clustere bazat pe scorul de siluet캒: {int(optimal_silhouette['Num캒r Clustere'])}")
        
        with tabs[1]:
            st.write("Metoda cotului (elbow method) analizeaz캒 rata de sc캒dere a iner탵iei. C캒ut캒m 'cotul' 칥n grafic.")
            fig = px.line(results_df, x='Num캒r Clustere', y='Iner탵ie',
                         title='Iner탵ie vs Num캒r Clustere')
            st.plotly_chart(fig, use_container_width=True)
            
            # Calcul캒m rata de sc캒dere a iner탵iei
            results_df['Rata Sc캒dere'] = results_df['Iner탵ie'].pct_change()
            optimal_elbow = results_df.loc[results_df['Rata Sc캒dere'].idxmin()]
            st.success(f"Sugestie pentru num캒rul optim de clustere bazat pe metoda cotului: {int(optimal_elbow['Num캒r Clustere'])}")
        
        with tabs[2]:
            st.write("Scorul Calinski-Harabasz m캒soar캒 raportul dintre dispersia inter-cluster 탳i intra-cluster. Valori mai mari indic캒 o clusterizare mai bun캒.")
            fig = px.line(results_df, x='Num캒r Clustere', y='Scor Calinski-Harabasz',
                         title='Scor Calinski-Harabasz vs Num캒r Clustere')
            st.plotly_chart(fig, use_container_width=True)
            
            # G캒sim num캒rul optim de clustere bazat pe scorul Calinski-Harabasz
            optimal_calinski = results_df.loc[results_df['Scor Calinski-Harabasz'].idxmax()]
            st.success(f"Num캒rul optim de clustere bazat pe scorul Calinski-Harabasz: {int(optimal_calinski['Num캒r Clustere'])}")
        
        # Aplic캒m K-means cu num캒rul optim de clustere
        n_clusters = int(optimal_silhouette['Num캒r Clustere'])
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        clusters = kmeans.fit_predict(X_scaled)
        
        # Calcul캒m scorul de siluet캒 final
        silhouette_avg = silhouette_score(X_scaled, clusters)
        
        # Ad캒ug캒m clusterele la DataFrame
        df_clustered = filtered_df.copy()
        df_clustered['Cluster'] = clusters
        
        # Afi탳캒m statistici despre clustere
        st.subheader("Statistici despre clustere")
        cluster_stats = df_clustered.groupby('Cluster')[feature_cols].mean()
        st.dataframe(cluster_stats, use_container_width=True)
        
        # Afi탳캒m scorul de siluet캒
        st.metric("Scor de siluet캒", f"{silhouette_avg:.3f}")
        
        # Vizualiz캒m clusterele 칥n spa탵iul 2D
        st.subheader("Vizualizare clustere")
        
        # Select캒m dou캒 variabile pentru vizualizare
        col1, col2 = st.columns(2)
        with col1:
            x_axis = st.selectbox("Axeaz캒 X", feature_cols, index=0, key="cluster_x")
        with col2:
            y_axis = st.selectbox("Axeaz캒 Y", feature_cols, index=1, key="cluster_y")
        
        # Cre캒m scatter plot
        fig = px.scatter(
            df_clustered,
            x=x_axis,
            y=y_axis,
            color='Cluster',
            title=f"Clustere 칥n spa탵iul {x_axis} vs {y_axis}",
            labels={x_axis: x_axis, y_axis: y_axis}
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Afi탳캒m distribu탵ia variabilelor 칥n clustere
        st.subheader("Distribu탵ia variabilelor 칥n clustere")
        for feature in feature_cols:
            fig = px.box(
                df_clustered,
                x='Cluster',
                y=feature,
                title=f"Distribu탵ia {feature} pe clustere"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Afi탳캒m c칙teva exemple din fiecare cluster
        st.subheader("Exemple din fiecare cluster")
        for cluster in range(n_clusters):
            st.write(f"Cluster {cluster} - {len(df_clustered[df_clustered['Cluster'] == cluster])} accidente")
            st.dataframe(
                df_clustered[df_clustered['Cluster'] == cluster][feature_cols].head(5),
                use_container_width=True
            )
    else:
        st.warning("Selecta탵i cel pu탵in dou캒 variabile pentru clusterizare!")