import streamlit as st
import pandas as pd
import numpy as np
import geopandas as gpd
import plotly.express as px
import seaborn as sns
import matplotlib.pyplot as plt
from datetime import datetime
from sklearn.impute import KNNImputer
from scipy import stats
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import statsmodels.api as sm
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, calinski_harabasz_score
from scalare_utils import aplica_scalare, adauga_sectiune_scalare

st.set_page_config(page_title="US Accidents Analysis", layout="wide")

with st.expander("📋 Dataset Description"):
    st.markdown("""
    ### Data Dictionary

    This dataset contains information about traffic accidents across the United States between 2016 and 2023. Here's what each column represents:

    #### Identification
    - **ID**: Unique identifier of the accident record
    - **Source**: Source of raw accident data

    #### Accident Details
    - **Severity**: Severity of the accident (1-4), where 1 indicates least impact on traffic (short delay) and 4 indicates significant impact (long delay)
    - **Start_Time**: Start time of the accident in local time zone
    - **End_Time**: When the impact of accident on traffic flow was dismissed
    - **Distance(mi)**: Length of the road affected by the accident in miles
    - **Description**: Human-provided description of the accident

    #### Location Information
    - **Start_Lat/Start_Lng**: GPS coordinates of the start point
    - **End_Lat/End_Lng**: GPS coordinates of the end point
    - **Street**: Street name
    - **City**: City name
    - **County**: County name
    - **State**: State abbreviation
    - **Zipcode**: ZIP code
    - **Country**: Country (US)
    - **Timezone**: Timezone based on location (eastern, central, etc.)

    #### Weather Conditions
    - **Airport_Code**: Closest airport-based weather station
    - **Weather_Timestamp**: Time of weather observation
    - **Temperature(F)**: Temperature in Fahrenheit
    - **Wind_Chill(F)**: Wind chill in Fahrenheit
    - **Humidity(%)**: Humidity percentage
    - **Pressure(in)**: Air pressure in inches
    - **Visibility(mi)**: Visibility in miles
    - **Wind_Direction**: Wind direction
    - **Wind_Speed(mph)**: Wind speed in mph
    - **Precipitation(in)**: Precipitation amount in inches
    - **Weather_Condition**: Weather condition (rain, snow, etc.)

    #### Point of Interest (POI) Annotations
    These boolean fields indicate presence of various features near the accident:
    - **Amenity**, **Bump**, **Crossing**, **Give_Way**, **Junction**, **No_Exit**
    - **Railway**, **Roundabout**, **Station**, **Stop**
    - **Traffic_Calming**, **Traffic_Signal**, **Turning_Loop**

    #### Time of Day Indicators
    - **Sunrise_Sunset**: Day or night based on sunrise/sunset
    - **Civil_Twilight**: Day or night based on civil twilight
    - **Nautical_Twilight**: Day or night based on nautical twilight
    - **Astronomical_Twilight**: Day or night based on astronomical twilight
    """)

#old load data, cu toate datele
@st.cache_data
def load_data():
    df = pd.read_csv('US_Accidents_Sample_1000_Per_Year.csv')

    df['Start_Time'] = pd.to_datetime(df['Start_Time'], format='mixed')
    df['End_Time'] = pd.to_datetime(df['End_Time'], format='mixed')

    df['Duration'] = (df['End_Time'] - df['Start_Time']).dt.total_seconds() / 60

    return df

st.title("📊 Analiza Exploratorie a Accidentelor Rutiere")

with st.sidebar:
    st.header("Meniu Principal")
    menu = st.radio(
        "Selectează secțiunea:",
        ["Analiză Generală", "Tratarea Valorilor Lipsă", "Identificarea Valorilor Extreme", "Grupări și Corelații",
         "Scalarea Datelor", "Codificare și Regresie", "Clusterizare"]
    )

    st.header("Filtrare Date")
    selected_years = st.slider("Selectează Anii",
                               min_value=2016,
                               max_value=2023,
                               value=(2023, 2023))

    st.markdown("---")
    st.markdown("### Alte filtre")
    severity_levels = st.multiselect("Niveluri de Severitate",
                                     options=[1, 2, 3, 4],
                                     default=[1, 2, 3, 4])

df = load_data()

filtered_df = df[
    (df['Start_Time'].dt.year >= selected_years[0]) &
    (df['Start_Time'].dt.year <= selected_years[1]) &
    (df['Severity'].isin(severity_levels))
    ]

if menu == "Analiză Generală":
    st.header("📊 Informații despre setul de date")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Număr de accidente", f"{filtered_df.shape[0]:,}")
    with col2:
        st.metric("Număr de coloane", f"{filtered_df.shape[1]}")
    with col3:
        st.metric("Perioada acoperită",
                  f"{filtered_df['Start_Time'].dt.year.min()} - {filtered_df['Start_Time'].dt.year.max()}")

    st.subheader("Primele înregistrări")
    st.dataframe(filtered_df.head(10), use_container_width=True)

    st.subheader("Informații despre tipurile de date")
    data_types = pd.DataFrame({
        'Coloană': filtered_df.dtypes.index,
        'Tip': filtered_df.dtypes.values,
        'Valori Nule': filtered_df.isna().sum().values,
        'Procent Nule': (filtered_df.isna().sum().values / len(filtered_df) * 100).round(2)
    })
    st.dataframe(data_types, use_container_width=True)

    st.subheader("Statistici de bază")
    st.dataframe(filtered_df.describe(), use_container_width=True)

elif menu == "Tratarea Valorilor Lipsă":
    st.header("🧩 Tratarea Valorilor Lipsă")

    na_cols = filtered_df.columns[filtered_df.isna().any()].tolist()

    if not na_cols:
        st.info("Nu există valori lipsă în datele filtrate!")
    else:
        selected_col = st.selectbox("Selectează coloana pentru tratarea valorilor lipsă", na_cols)

        st.subheader(f"Vizualizarea valorilor lipsă pentru coloana {selected_col}")

        col1, col2 = st.columns(2)
        with col1:
            st.metric("Total valori lipsă", filtered_df[selected_col].isna().sum())
            st.metric("Procent valori lipsă",
                      f"{(filtered_df[selected_col].isna().sum() / len(filtered_df) * 100):.2f}%")

        with col2:
            if pd.api.types.is_numeric_dtype(filtered_df[selected_col]):
                fig, ax = plt.subplots(figsize=(6, 3))
                filtered_df[selected_col].hist(ax=ax)
                st.pyplot(fig)

        st.subheader("Metode de tratare a valorilor lipsă")

        tabs = st.tabs(
            ["Metoda 1: Înlocuire cu media/mediana/mod", "Metoda 2: Înlocuire cu KNN", "Metoda 3: Interpolare"])

        with tabs[0]:
            st.markdown("#### Înlocuire cu statistici")

            if pd.api.types.is_numeric_dtype(filtered_df[selected_col]):
                method = st.radio("Alege metoda de înlocuire:", ["Media", "Mediana"])

                if method == "Media":
                    replace_value = filtered_df[selected_col].mean()
                    df_replaced = filtered_df.copy()
                    df_replaced[selected_col] = df_replaced[selected_col].fillna(replace_value)

                    st.success(f"Valorile lipsă au fost înlocuite cu media: {replace_value:.2f}")

                elif method == "Mediana":
                    replace_value = filtered_df[selected_col].median()
                    df_replaced = filtered_df.copy()
                    df_replaced[selected_col] = df_replaced[selected_col].fillna(replace_value)

                    st.success(f"Valorile lipsă au fost înlocuite cu mediana: {replace_value:.2f}")

                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("##### Înainte de înlocuire")
                    st.dataframe(filtered_df[[selected_col]].describe(), use_container_width=True)

                with col2:
                    st.markdown("##### După înlocuire")
                    st.dataframe(df_replaced[[selected_col]].describe(), use_container_width=True)

            else:
                mode_value = filtered_df[selected_col].mode()[0]
                df_replaced = filtered_df.copy()
                df_replaced[selected_col] = df_replaced[selected_col].fillna(mode_value)

                st.success(f"Pentru coloana categorică, valorile lipsă au fost înlocuite cu modul: {mode_value}")

        with tabs[1]:
            st.markdown("#### Înlocuire cu KNN")

            if pd.api.types.is_numeric_dtype(filtered_df[selected_col]):
                k_neighbors = st.slider("Număr de vecini (K)", 1, 10, 5)

                numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()

                # Selectăm doar câteva coloane numerice pentru demonstrație
                cols_for_imputation = st.multiselect(
                    "Selectează coloanele pentru imputare (se recomandă coloane corelate)",
                    numeric_cols,
                    default=[selected_col] + [c for c in numeric_cols if c != selected_col][:2]
                )

                if len(cols_for_imputation) > 1:
                    imputer = KNNImputer(n_neighbors=k_neighbors)

                    # Extragem doar coloanele relevante și eliminăm rândurile unde toate valorile sunt NA
                    subset_df = filtered_df[cols_for_imputation].copy()
                    subset_df = subset_df.dropna(how='all')

                    # Aplicăm imputarea
                    imputed_array = imputer.fit_transform(subset_df)
                    imputed_df = pd.DataFrame(imputed_array, columns=cols_for_imputation)

                    st.success(f"Valorile lipsă au fost înlocuite folosind metoda KNN cu {k_neighbors} vecini")

                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("##### Înainte de înlocuire")
                        st.dataframe(filtered_df[selected_col].describe(), use_container_width=True)

                    with col2:
                        st.markdown("##### După înlocuire")
                        st.dataframe(imputed_df[selected_col].describe(), use_container_width=True)
                else:
                    st.warning("Selectați cel puțin 2 coloane pentru imputare KNN")
            else:
                st.warning("Metoda KNN este aplicabilă doar pentru coloane numerice")

        with tabs[2]:
            st.markdown("#### Interpolare")

            if pd.api.types.is_numeric_dtype(filtered_df[selected_col]):
                method = st.radio("Metoda de interpolare:", ["Linear", "Polynomial", "Spline"])

                df_interpolated = filtered_df.copy()

                if method == "Linear":
                    df_interpolated[selected_col] = df_interpolated[selected_col].interpolate(method='linear')
                    st.success("Interpolare liniară aplicată")

                elif method == "Polynomial":
                    df_interpolated[selected_col] = df_interpolated[selected_col].interpolate(method='polynomial',
                                                                                              order=2)
                    st.success("Interpolare polinomială de gradul 2 aplicată")

                elif method == "Spline":
                    df_interpolated[selected_col] = df_interpolated[selected_col].interpolate(method='spline', order=3)
                    st.success("Interpolare spline cubică aplicată")

                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("##### Înainte de interpolare")
                    st.dataframe(filtered_df[[selected_col]].head(20), use_container_width=True)

                with col2:
                    st.markdown("##### După interpolare")
                    st.dataframe(df_interpolated[[selected_col]].head(20), use_container_width=True)

                st.markdown("##### Comparație statistici")
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("Înainte")
                    st.dataframe(filtered_df[selected_col].describe(), use_container_width=True)

                with col2:
                    st.markdown("După")
                    st.dataframe(df_interpolated[selected_col].describe(), use_container_width=True)
            else:
                st.warning("Interpolarea este aplicabilă doar pentru coloane numerice")

elif menu == "Identificarea Valorilor Extreme":
    st.header("🔍 Identificarea și Tratarea Valorilor Extreme")

    numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()

    col_for_outlier = st.selectbox("Selectează coloana pentru analiza outlierilor", numeric_cols)

    st.subheader(f"Analiză outlieri pentru {col_for_outlier}")

    col1, col2 = st.columns([1, 2])

    with col1:
        st.markdown("### Statistici")
        # Calculează outlieri folosind IQR
        Q1 = filtered_df[col_for_outlier].quantile(0.25)
        Q3 = filtered_df[col_for_outlier].quantile(0.75)
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        outliers = \
        filtered_df[(filtered_df[col_for_outlier] < lower_bound) | (filtered_df[col_for_outlier] > upper_bound)][
            col_for_outlier]

        st.metric("Număr de outlieri", outliers.count())
        st.metric("Procent outlieri", f"{(outliers.count() / filtered_df[col_for_outlier].count() * 100):.2f}%")
        st.metric("Limita inferioară", f"{lower_bound:.2f}")
        st.metric("Limita superioară", f"{upper_bound:.2f}")

        if outliers.count() > 0:
            st.metric("Minim outlieri", f"{outliers.min():.2f}")
            st.metric("Maxim outlieri", f"{outliers.max():.2f}")

    with col2:
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.boxplot(x=filtered_df[col_for_outlier], ax=ax)
        ax.set_title(f"Boxplot pentru {col_for_outlier}")
        st.pyplot(fig)

        # Histogramă cu distribuție
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.histplot(filtered_df[col_for_outlier], kde=True, ax=ax)
        ax.axvline(lower_bound, color='r', linestyle='--')
        ax.axvline(upper_bound, color='r', linestyle='--')
        ax.set_title(f"Histogramă cu limite outlieri pentru {col_for_outlier}")
        st.pyplot(fig)

    st.subheader("Metode de tratare a outlierilor")

    outlier_method = st.radio(
        "Selectează metoda de tratare:",
        ["Vizualizare fără tratare", "Înlocuire cu limite", "Transformare logaritmică", "Înlocuire cu valori calculate"]
    )

    if outlier_method == "Vizualizare fără tratare":
        st.dataframe(filtered_df[[col_for_outlier]].describe(), use_container_width=True)

        # Prezintă top 10 valori extreme
        if outliers.count() > 0:
            st.subheader("Top 10 valori extreme")
            extreme_values = outliers.sort_values(ascending=False).head(10)
            st.dataframe(pd.DataFrame(extreme_values), use_container_width=True)

    elif outlier_method == "Înlocuire cu limite":
        df_capped = filtered_df.copy()

        df_capped[col_for_outlier] = df_capped[col_for_outlier].clip(lower=lower_bound, upper=upper_bound)

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### Înainte de tratare")
            st.dataframe(filtered_df[col_for_outlier].describe(), use_container_width=True)

            fig, ax = plt.subplots(figsize=(8, 4))
            sns.boxplot(x=filtered_df[col_for_outlier], ax=ax)
            st.pyplot(fig)

        with col2:
            st.markdown("##### După înlocuire cu limite")
            st.dataframe(df_capped[col_for_outlier].describe(), use_container_width=True)

            fig, ax = plt.subplots(figsize=(8, 4))
            sns.boxplot(x=df_capped[col_for_outlier], ax=ax)
            st.pyplot(fig)

    elif outlier_method == "Transformare logaritmică":
        if (filtered_df[col_for_outlier] <= 0).any():
            st.warning(
                "Transformarea logaritmică necesită valori pozitive. Adăugăm o constantă pentru a face toate valorile pozitive.")
            min_val = filtered_df[col_for_outlier].min()
            constant = abs(min_val) + 1 if min_val <= 0 else 0

            df_log = filtered_df.copy()
            df_log[col_for_outlier] = np.log(df_log[col_for_outlier] + constant)

            st.success(
                f"Am adăugat constanta {constant} pentru a face toate valorile pozitive înainte de transformarea log")
        else:
            df_log = filtered_df.copy()
            df_log[col_for_outlier] = np.log(df_log[col_for_outlier])

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### Distribuția originală")
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.histplot(filtered_df[col_for_outlier], kde=True, ax=ax)
            st.pyplot(fig)

        with col2:
            st.markdown("##### Distribuția după transformarea log")
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.histplot(df_log[col_for_outlier], kde=True, ax=ax)
            st.pyplot(fig)

        st.dataframe(df_log[col_for_outlier].describe(), use_container_width=True)

    elif outlier_method == "Înlocuire cu valori calculate":
        replace_method = st.radio(
            "Metodă de înlocuire:",
            ["Medie", "Mediană", "Calcul bazat pe percentile"]
        )

        df_replaced = filtered_df.copy()

        if replace_method == "Medie":
            # Excludem outlieri din calculul mediei
            mean_no_outliers = filtered_df[(filtered_df[col_for_outlier] >= lower_bound) &
                                           (filtered_df[col_for_outlier] <= upper_bound)][col_for_outlier].mean()

            # Înlocuim doar outlieri
            df_replaced.loc[(df_replaced[col_for_outlier] < lower_bound), col_for_outlier] = mean_no_outliers
            df_replaced.loc[(df_replaced[col_for_outlier] > upper_bound), col_for_outlier] = mean_no_outliers

            st.success(f"Outlieri înlocuiți cu media fără outlieri: {mean_no_outliers:.2f}")

        elif replace_method == "Mediană":
            median = filtered_df[col_for_outlier].median()

            df_replaced.loc[(df_replaced[col_for_outlier] < lower_bound), col_for_outlier] = median
            df_replaced.loc[(df_replaced[col_for_outlier] > upper_bound), col_for_outlier] = median

            st.success(f"Outlieri înlocuiți cu mediana: {median:.2f}")

        elif replace_method == "Calcul bazat pe percentile":
            p10 = filtered_df[col_for_outlier].quantile(0.10)
            p90 = filtered_df[col_for_outlier].quantile(0.90)

            df_replaced.loc[(df_replaced[col_for_outlier] < lower_bound), col_for_outlier] = p10
            df_replaced.loc[(df_replaced[col_for_outlier] > upper_bound), col_for_outlier] = p90

            st.success(f"Outlieri mici înlocuiți cu percentila 10: {p10:.2f}")
            st.success(f"Outlieri mari înlocuiți cu percentila 90: {p90:.2f}")

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### Boxplot înainte de înlocuire")
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.boxplot(x=filtered_df[col_for_outlier], ax=ax)
            st.pyplot(fig)

        with col2:
            st.markdown("##### Boxplot după înlocuire")
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.boxplot(x=df_replaced[col_for_outlier], ax=ax)
            st.pyplot(fig)

        st.subheader("Comparație statistici")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### Înainte")
            st.dataframe(filtered_df[col_for_outlier].describe(), use_container_width=True)

        with col2:
            st.markdown("##### După")
            st.dataframe(df_replaced[col_for_outlier].describe(), use_container_width=True)

elif menu == "Grupări și Corelații":
    st.header("📊 Grupări și Corelații")

    tabs = st.tabs(["Corelații", "Grupări", "Funcții Agregate"])

    with tabs[0]:
        st.subheader("Matricea de corelație")

        numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()
        selected_cols = st.multiselect(
            "Selectează coloanele pentru analiza corelațiilor",
            numeric_cols,
            default=numeric_cols[:8]  # Primele 8 coloane numerice
        )

        if not selected_cols:
            st.warning("Selectați cel puțin o coloană!")
        else:
            corr_method = st.radio("Metoda de corelație:", ["Pearson", "Spearman", "Kendall"])

            fig, ax = plt.subplots(figsize=(12, 10))
            corr_matrix = filtered_df[selected_cols].corr(method=corr_method.lower())

            mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
            sns.heatmap(corr_matrix, mask=mask, annot=True, fmt=".2f",
                        cmap="coolwarm", ax=ax, cbar_kws={"shrink": .8})

            plt.title(f"Matrice de corelație folosind metoda {corr_method}")
            plt.tight_layout()
            st.pyplot(fig)

            st.subheader("Selectează perechi de coloane pentru analiză")

            col1, col2 = st.columns(2)
            with col1:
                x_col = st.selectbox("Coloana X", selected_cols, index=0)
            with col2:
                y_col = st.selectbox("Coloana Y", [c for c in selected_cols if c != x_col], index=0)

            fig, ax = plt.subplots(figsize=(10, 6))
            sns.regplot(x=filtered_df[x_col], y=filtered_df[y_col], ax=ax)
            plt.title(f"Relația dintre {x_col} și {y_col}")
            plt.tight_layout()
            st.pyplot(fig)

            st.metric(f"Coeficient de corelație {corr_method}",
                      f"{filtered_df[x_col].corr(filtered_df[y_col], method=corr_method.lower()):.3f}")

    with tabs[1]:
        st.subheader("Gruparea datelor")

        # Coloane pentru grupare
        all_cols = filtered_df.columns.tolist()
        categorical_cols = filtered_df.select_dtypes(include=['object', 'category']).columns.tolist()
        date_cols = ['Start_Time']

        # Adăugăm coloane derivate pentru grupare temporală
        filtered_df['Month'] = filtered_df['Start_Time'].dt.month
        filtered_df['DayOfWeek'] = filtered_df['Start_Time'].dt.dayofweek
        filtered_df['Hour'] = filtered_df['Start_Time'].dt.hour

        group_by_options = categorical_cols + ['Month', 'DayOfWeek', 'Hour', 'Severity']

        col1, col2 = st.columns(2)
        with col1:
            groupby_col = st.selectbox("Grupează după", group_by_options)

        with col2:
            agg_col = st.selectbox("Aplică funcție pe coloana",
                                   [c for c in filtered_df.select_dtypes(include=[np.number]).columns if
                                    c != groupby_col])

        agg_func = st.radio("Funcție de agregare", ["Număr", "Medie", "Sumă", "Minim", "Maxim", "Mediană"])

        if agg_func == "Număr":
            result_df = filtered_df.groupby(groupby_col).size().reset_index(name='Număr')
        elif agg_func == "Medie":
            result_df = filtered_df.groupby(groupby_col)[agg_col].mean().reset_index(name=f'Medie {agg_col}')
        elif agg_func == "Sumă":
            result_df = filtered_df.groupby(groupby_col)[agg_col].sum().reset_index(name=f'Sumă {agg_col}')
        elif agg_func == "Minim":
            result_df = filtered_df.groupby(groupby_col)[agg_col].min().reset_index(name=f'Minim {agg_col}')
        elif agg_func == "Maxim":
            result_df = filtered_df.groupby(groupby_col)[agg_col].max().reset_index(name=f'Maxim {agg_col}')
        elif agg_func == "Mediană":
            result_df = filtered_df.groupby(groupby_col)[agg_col].median().reset_index(name=f'Mediană {agg_col}')

        # Sortăm rezultatul
        if agg_func == "Număr":
            result_df = result_df.sort_values(by='Număr', ascending=False)
        else:
            result_df = result_df.sort_values(by=result_df.columns[1], ascending=False)

        st.subheader("Rezultat grupare")
        st.dataframe(result_df, use_container_width=True)

        # Vizualizăm rezultatul cu un grafic
        fig = px.bar(
            result_df.head(20),
            x=groupby_col,
            y=result_df.columns[1],
            title=f"{agg_func} de {agg_col if agg_func != 'Număr' else 'accidente'} grupat după {groupby_col}"
        )
        fig.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig, use_container_width=True)

    with tabs[2]:
        st.subheader("Funcții de agregare multiple")

        all_cols = filtered_df.columns.tolist()
        categorical_cols = filtered_df.select_dtypes(include=['object', 'category']).columns.tolist()
        numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()

        col1, col2 = st.columns(2)
        with col1:
            groupby_cols = st.multiselect("Grupează după (selectează una sau mai multe coloane)",
                                          categorical_cols + ['Month', 'DayOfWeek', 'Hour', 'Severity'],
                                          default=[categorical_cols[0] if categorical_cols else 'Severity'])

        with col2:
            agg_cols = st.multiselect("Coloane pentru agregare",
                                      [c for c in numeric_cols if c not in groupby_cols],
                                      default=[numeric_cols[0] if numeric_cols else 'Duration'])

        agg_funcs = st.multiselect("Funcții de agregare",
                                   ["count", "mean", "sum", "min", "max", "median", "std", "var"],
                                   default=["count", "mean"])

        if not groupby_cols:
            st.warning("Selectați cel puțin o coloană pentru grupare!")
        elif not agg_cols:
            st.warning("Selectați cel puțin o coloană pentru agregare!")
        elif not agg_funcs:
            st.warning("Selectați cel puțin o funcție de agregare!")
        else:
            # Construim dicționarul pentru agregare
            agg_dict = {col: agg_funcs for col in agg_cols}

            result_df = filtered_df.groupby(groupby_cols).agg(agg_dict)

            # Resetăm index-ul pentru afișare mai ușoară
            result_df = result_df.reset_index()

            # Afișăm rezultatul
            st.dataframe(result_df, use_container_width=True)

            # Opțiune pentru descărcare
            csv = result_df.to_csv(index=False)
            st.download_button(
                label="Descarcă rezultatele în CSV",
                data=csv,
                file_name=f"grupare_{'_'.join(groupby_cols)}.csv",
                mime="text/csv"
            )

            # Vizualizare grafică pentru prima funcție de agregare și prima coloană
            if len(groupby_cols) == 1 and len(result_df) <= 25:
                agg_col_name = f"{agg_cols[0]}_{agg_funcs[0]}"

                fig = px.bar(
                    result_df.head(25),
                    x=groupby_cols[0],
                    y=agg_col_name,
                    title=f"{agg_funcs[0]} de {agg_cols[0]} grupat după {groupby_cols[0]}"
                )
                fig.update_layout(xaxis_tickangle=-45)
                st.plotly_chart(fig, use_container_width=True)

elif menu == "Scalarea Datelor":
    # Aplicăm funcția pentru vizualizarea și aplicarea metodelor de scalare
    st.header("🔄 Metode de Scalare a Datelor")
    adauga_sectiune_scalare(filtered_df, sidebar=False)

# Adăugăm o nouă opțiune pentru BoxPlot interactiv
st.sidebar.markdown("---")
if st.sidebar.checkbox("Activează BoxPlot Interactiv"):
    st.header("📊 BoxPlot Interactiv")

    numeric_columns = filtered_df.select_dtypes(include=[np.number]).columns.tolist()
    selected_column = st.selectbox("Selectează coloana pentru BoxPlot", numeric_columns)

    col1, col2 = st.columns([2, 1])

    with col1:
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.boxplot(y=filtered_df[selected_column], ax=ax)
        ax.set_title(f"BoxPlot pentru {selected_column}")
        st.pyplot(fig)

    with col2:
        st.markdown("### Statistici")
        stats = filtered_df[selected_column].describe()

        # Calculăm manual IQR pentru limite de outlieri
        Q1 = stats["25%"]
        Q3 = stats["75%"]
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        outliers_count = filtered_df[(filtered_df[selected_column] < lower_bound) |
                                     (filtered_df[selected_column] > upper_bound)].shape[0]

        st.metric("Minim", f"{stats['min']:.2f}")
        st.metric("Q1 (25%)", f"{Q1:.2f}")
        st.metric("Mediană", f"{stats['50%']:.2f}")
        st.metric("Q3 (75%)", f"{Q3:.2f}")
        st.metric("Maxim", f"{stats['max']:.2f}")
        st.metric("IQR", f"{IQR:.2f}")
        st.metric("Limita inferioară", f"{lower_bound:.2f}")
        st.metric("Limita superioară", f"{upper_bound:.2f}")
        st.metric("Număr outlieri", f"{outliers_count} ({outliers_count / len(filtered_df) * 100:.1f}%)")

    if st.checkbox("Arată histograma"):
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.histplot(filtered_df[selected_column], kde=True, ax=ax)
        plt.axvline(lower_bound, color='r', linestyle='--', label='Limite outlieri')
        plt.axvline(upper_bound, color='r', linestyle='--')
        plt.legend()
        st.pyplot(fig)

elif menu == "Codificare și Regresie":
    st.header("🔢 Codificare și Analiză de Regresie")
    
    tabs = st.tabs(["Codificare Date", "Regresie Logistică", "Regresie Multiplă"])
    
    with tabs[0]:
        st.subheader("Codificare Date")
        
        # Selectăm coloanele categorice pentru codificare
        categorical_cols = filtered_df.select_dtypes(include=['object']).columns.tolist()
        selected_col = st.selectbox("Selectează coloana pentru codificare", categorical_cols)
        
        encoding_method = st.radio("Alege metoda de codificare:", ["Label Encoding", "One-Hot Encoding"])
        
        if encoding_method == "Label Encoding":
            le = LabelEncoder()
            encoded_values = le.fit_transform(filtered_df[selected_col].fillna('Missing'))
            
            # Creăm un DataFrame pentru vizualizare
            encoding_df = pd.DataFrame({
                'Valoare Originală': filtered_df[selected_col].fillna('Missing'),
                'Valoare Codificată': encoded_values
            }).drop_duplicates().sort_values('Valoare Codificată')
            
            st.dataframe(encoding_df, use_container_width=True)
            
        else:  # One-Hot Encoding
            ohe = OneHotEncoder(sparse=False)
            encoded_values = ohe.fit_transform(filtered_df[[selected_col]].fillna('Missing'))
            
            # Creăm un DataFrame pentru vizualizare
            feature_names = [f"{selected_col}_{val}" for val in ohe.categories_[0]]
            encoding_df = pd.DataFrame(encoded_values, columns=feature_names)
            
            st.dataframe(encoding_df.head(), use_container_width=True)
            
            # Vizualizăm distribuția valorilor codificate
            fig = px.bar(encoding_df.sum(), title=f"Distribuția valorilor codificate pentru {selected_col}")
            st.plotly_chart(fig)
    
    with tabs[1]:
        st.subheader("Regresie Logistică")
        
        # Selectăm variabilele pentru regresie logistică
        target_col = st.selectbox("Selectează variabila țintă (binară)", 
                                ['Severity', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit'],
                                key="logistic_target")
        
        feature_cols = st.multiselect("Selectează variabilele predictoare (numerice)",
                                    filtered_df.select_dtypes(include=[np.number]).columns.tolist(),
                                    default=['Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)'],
                                    key="logistic_features")
        
        if len(feature_cols) > 0:
            # Pregătim datele
            X = filtered_df[feature_cols].fillna(filtered_df[feature_cols].mean())
            y = (filtered_df[target_col] > filtered_df[target_col].median()).astype(int)
            
            # Împărțim datele în set de antrenare și test
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            # Antrenăm modelul
            model = LogisticRegression(max_iter=1000)
            model.fit(X_train, y_train)
            
            # Evaluăm modelul
            y_pred = model.predict(X_test)
            
            st.subheader("Rezultate Model")
            st.text(classification_report(y_test, y_pred))
            
            # Vizualizăm matricea de confuzie
            cm = confusion_matrix(y_test, y_pred)
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
            ax.set_xlabel('Predicted')
            ax.set_ylabel('Actual')
            st.pyplot(fig)
            
            # Afișăm coeficienții modelului
            coef_df = pd.DataFrame({
                'Feature': feature_cols,
                'Coefficient': model.coef_[0]
            })
            st.dataframe(coef_df.sort_values('Coefficient', ascending=False), use_container_width=True)
    
    with tabs[2]:
        st.subheader("Regresie Multiplă")
        
        # Selectăm variabilele pentru regresie multiplă
        target_col = st.selectbox("Selectează variabila țintă (numerică)", 
                                ['Duration', 'Distance(mi)', 'Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)'],
                                key="multiple_target")
        
        feature_cols = st.multiselect("Selectează variabilele predictoare (numerice)",
                                    filtered_df.select_dtypes(include=[np.number]).columns.tolist(),
                                    default=['Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)'],
                                    key="multiple_features")
        
        if len(feature_cols) > 0:
            # Pregătim datele
            X = filtered_df[feature_cols].fillna(filtered_df[feature_cols].mean())
            y = filtered_df[target_col].fillna(filtered_df[target_col].mean())
            
            # Adăugăm constanta pentru statsmodels
            X = sm.add_constant(X)
            
            # Antrenăm modelul
            model = sm.OLS(y, X).fit()
            
            # Afișăm rezultatele
            st.subheader("Rezultate Model")
            st.text(model.summary())
            
            # Vizualizăm reziduurile
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.scatter(model.fittedvalues, model.resid)
            ax.axhline(y=0, color='r', linestyle='--')
            ax.set_xlabel('Valori Prezise')
            ax.set_ylabel('Reziduuri')
            st.pyplot(fig)
            
            # Vizualizăm coeficienții
            coef_df = pd.DataFrame({
                'Feature': ['const'] + feature_cols,
                'Coefficient': model.params,
                'P-value': model.pvalues
            })
            st.dataframe(coef_df.sort_values('P-value'), use_container_width=True)

elif menu == "Clusterizare":
    st.header("🔍 Analiza Clusterizării")
    
    # Selectăm variabilele pentru clusterizare
    numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()
    feature_cols = st.multiselect(
        "Selectează variabilele pentru clusterizare",
        numeric_cols,
        default=['Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)'],
        key="cluster_features"
    )
    
    if len(feature_cols) > 1:
        # Pregătim datele
        X = filtered_df[feature_cols].fillna(filtered_df[feature_cols].mean())
        
        # Scalăm datele
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Determinăm numărul optim de clustere
        max_clusters = min(10, len(filtered_df) - 1)
        
        # Calculăm metricile pentru diferite numere de clustere
        silhouette_scores = []
        inertia_scores = []
        calinski_scores = []
        
        for n_clusters in range(2, max_clusters + 1):
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            clusters = kmeans.fit_predict(X_scaled)
            
            # Calculăm scorurile
            silhouette_scores.append(silhouette_score(X_scaled, clusters))
            inertia_scores.append(kmeans.inertia_)
            calinski_scores.append(calinski_harabasz_score(X_scaled, clusters))
        
        # Creăm un DataFrame cu rezultatele
        results_df = pd.DataFrame({
            'Număr Clustere': range(2, max_clusters + 1),
            'Scor Siluetă': silhouette_scores,
            'Inerție': inertia_scores,
            'Scor Calinski-Harabasz': calinski_scores
        })
        
        # Afișăm rezultatele
        st.subheader("Determinarea numărului optim de clustere")
        
        # Creăm un tab pentru fiecare metodă
        tabs = st.tabs(["Scor Siluetă", "Metoda Cotului", "Calinski-Harabasz"])
        
        with tabs[0]:
            st.write("Scorul de siluetă măsoară cât de bine sunt separate clusterele. Valori mai mari indică o clusterizare mai bună.")
            fig = px.line(results_df, x='Număr Clustere', y='Scor Siluetă',
                         title='Scor Siluetă vs Număr Clustere')
            st.plotly_chart(fig, use_container_width=True)
            
            # Găsim numărul optim de clustere bazat pe scorul de siluetă
            optimal_silhouette = results_df.loc[results_df['Scor Siluetă'].idxmax()]
            st.success(f"Numărul optim de clustere bazat pe scorul de siluetă: {int(optimal_silhouette['Număr Clustere'])}")
        
        with tabs[1]:
            st.write("Metoda cotului (elbow method) analizează rata de scădere a inerției. Căutăm 'cotul' în grafic.")
            fig = px.line(results_df, x='Număr Clustere', y='Inerție',
                         title='Inerție vs Număr Clustere')
            st.plotly_chart(fig, use_container_width=True)
            
            # Calculăm rata de scădere a inerției
            results_df['Rata Scădere'] = results_df['Inerție'].pct_change()
            optimal_elbow = results_df.loc[results_df['Rata Scădere'].idxmin()]
            st.success(f"Sugestie pentru numărul optim de clustere bazat pe metoda cotului: {int(optimal_elbow['Număr Clustere'])}")
        
        with tabs[2]:
            st.write("Scorul Calinski-Harabasz măsoară raportul dintre dispersia inter-cluster și intra-cluster. Valori mai mari indică o clusterizare mai bună.")
            fig = px.line(results_df, x='Număr Clustere', y='Scor Calinski-Harabasz',
                         title='Scor Calinski-Harabasz vs Număr Clustere')
            st.plotly_chart(fig, use_container_width=True)
            
            # Găsim numărul optim de clustere bazat pe scorul Calinski-Harabasz
            optimal_calinski = results_df.loc[results_df['Scor Calinski-Harabasz'].idxmax()]
            st.success(f"Numărul optim de clustere bazat pe scorul Calinski-Harabasz: {int(optimal_calinski['Număr Clustere'])}")
        
        # Aplicăm K-means cu numărul optim de clustere
        n_clusters = int(optimal_silhouette['Număr Clustere'])
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        clusters = kmeans.fit_predict(X_scaled)
        
        # Calculăm scorul de siluetă final
        silhouette_avg = silhouette_score(X_scaled, clusters)
        
        # Adăugăm clusterele la DataFrame
        df_clustered = filtered_df.copy()
        df_clustered['Cluster'] = clusters
        
        # Afișăm statistici despre clustere
        st.subheader("Statistici despre clustere")
        cluster_stats = df_clustered.groupby('Cluster')[feature_cols].mean()
        st.dataframe(cluster_stats, use_container_width=True)
        
        # Afișăm scorul de siluetă
        st.metric("Scor de siluetă", f"{silhouette_avg:.3f}")
        
        # Vizualizăm clusterele în spațiul 2D
        st.subheader("Vizualizare clustere")
        
        # Selectăm două variabile pentru vizualizare
        col1, col2 = st.columns(2)
        with col1:
            x_axis = st.selectbox("Axează X", feature_cols, index=0, key="cluster_x")
        with col2:
            y_axis = st.selectbox("Axează Y", feature_cols, index=1, key="cluster_y")
        
        # Creăm scatter plot
        fig = px.scatter(
            df_clustered,
            x=x_axis,
            y=y_axis,
            color='Cluster',
            title=f"Clustere în spațiul {x_axis} vs {y_axis}",
            labels={x_axis: x_axis, y_axis: y_axis}
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Afișăm distribuția variabilelor în clustere
        st.subheader("Distribuția variabilelor în clustere")
        for feature in feature_cols:
            fig = px.box(
                df_clustered,
                x='Cluster',
                y=feature,
                title=f"Distribuția {feature} pe clustere"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Afișăm câteva exemple din fiecare cluster
        st.subheader("Exemple din fiecare cluster")
        for cluster in range(n_clusters):
            st.write(f"Cluster {cluster} - {len(df_clustered[df_clustered['Cluster'] == cluster])} accidente")
            st.dataframe(
                df_clustered[df_clustered['Cluster'] == cluster][feature_cols].head(5),
                use_container_width=True
            )
    else:
        st.warning("Selectați cel puțin două variabile pentru clusterizare!")