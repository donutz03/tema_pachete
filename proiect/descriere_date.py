import streamlit as st
import pandas as pd
import numpy as np
import geopandas as gpd
import plotly.express as px
import seaborn as sns
import matplotlib.pyplot as plt
from datetime import datetime
from sklearn.impute import KNNImputer
from scipy import stats
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import statsmodels.api as sm
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, calinski_harabasz_score
from scalare_utils import aplica_scalare, adauga_sectiune_scalare
import plotly.graph_objects as go

st.set_page_config(page_title="US Accidents Analysis", layout="wide")

with st.expander("ğŸ“‹ Dataset Description"):
    st.markdown("""
    ### Data Dictionary

    This dataset contains information about traffic accidents across the United States between 2016 and 2023. Here's what each column represents:

    #### Identification
    - **ID**: Unique identifier of the accident record
    - **Source**: Source of raw accident data

    #### Accident Details
    - **Severity**: Severity of the accident (1-4), where 1 indicates least impact on traffic (short delay) and 4 indicates significant impact (long delay)
    - **Start_Time**: Start time of the accident in local time zone
    - **End_Time**: When the impact of accident on traffic flow was dismissed
    - **Distance(mi)**: Length of the road affected by the accident in miles
    - **Description**: Human-provided description of the accident

    #### Location Information
    - **Start_Lat/Start_Lng**: GPS coordinates of the start point
    - **End_Lat/End_Lng**: GPS coordinates of the end point
    - **Street**: Street name
    - **City**: City name
    - **County**: County name
    - **State**: State abbreviation
    - **Zipcode**: ZIP code
    - **Country**: Country (US)
    - **Timezone**: Timezone based on location (eastern, central, etc.)

    #### Weather Conditions
    - **Airport_Code**: Closest airport-based weather station
    - **Weather_Timestamp**: Time of weather observation
    - **Temperature(F)**: Temperature in Fahrenheit
    - **Wind_Chill(F)**: Wind chill in Fahrenheit
    - **Humidity(%)**: Humidity percentage
    - **Pressure(in)**: Air pressure in inches
    - **Visibility(mi)**: Visibility in miles
    - **Wind_Direction**: Wind direction
    - **Wind_Speed(mph)**: Wind speed in mph
    - **Precipitation(in)**: Precipitation amount in inches
    - **Weather_Condition**: Weather condition (rain, snow, etc.)

    #### Point of Interest (POI) Annotations
    These boolean fields indicate presence of various features near the accident:
    - **Amenity**, **Bump**, **Crossing**, **Give_Way**, **Junction**, **No_Exit**
    - **Railway**, **Roundabout**, **Station**, **Stop**
    - **Traffic_Calming**, **Traffic_Signal**, **Turning_Loop**

    #### Time of Day Indicators
    - **Sunrise_Sunset**: Day or night based on sunrise/sunset
    - **Civil_Twilight**: Day or night based on civil twilight
    - **Nautical_Twilight**: Day or night based on nautical twilight
    - **Astronomical_Twilight**: Day or night based on astronomical twilight
    """)

@st.cache_data
def load_data():
    df = pd.read_csv('US_Accidents_Sample_1000_Per_Year.csv')

    # Convertim coloanele de timp
    df['Start_Time'] = pd.to_datetime(df['Start_Time'], errors='coerce')
    df['End_Time'] = pd.to_datetime(df['End_Time'], errors='coerce')

    # CalculÄƒm durata
    df['Duration'] = (df['End_Time'] - df['Start_Time']).dt.total_seconds() / 60

    # Convertim coloanele de tip object Ã®n string
    for col in df.select_dtypes(include='object').columns:
        if not pd.api.types.is_datetime64_any_dtype(df[col]):
            df[col] = df[col].astype(str)

    return df

st.title("ğŸ“Š Analiza Exploratorie a Accidentelor Rutiere")

with st.sidebar:
    st.header("Meniu Principal")
    menu = st.radio(
        "SelecteazÄƒ secÈ›iunea:",
        ["AnalizÄƒ GeneralÄƒ", "Tratarea Valorilor LipsÄƒ", "Identificarea Valorilor Extreme", "GrupÄƒri È™i CorelaÈ›ii",
         "Scalarea Datelor", "Codificare È™i Regresie", "Clusterizare"]
    )

    st.header("Filtrare Date")
    selected_years = st.slider("SelecteazÄƒ Anii",
                               min_value=2016,
                               max_value=2023,
                               value=(2023, 2023))

    st.markdown("---")
    st.markdown("### Alte filtre")
    severity_levels = st.multiselect("Niveluri de Severitate",
                                     options=[1, 2, 3, 4],
                                     default=[1, 2, 3, 4])

df = load_data()

filtered_df = df[
    (df['Start_Time'].dt.year >= selected_years[0]) &
    (df['Start_Time'].dt.year <= selected_years[1]) &
    (df['Severity'].isin(severity_levels))
    ]

if menu == "AnalizÄƒ GeneralÄƒ":
    st.header("ğŸ“Š InformaÈ›ii despre setul de date")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("NumÄƒr de accidente", f"{filtered_df.shape[0]:,}")
    with col2:
        st.metric("NumÄƒr de coloane", f"{filtered_df.shape[1]}")
    with col3:
        st.metric("Perioada acoperitÄƒ",
                  f"{filtered_df['Start_Time'].dt.year.min()} - {filtered_df['Start_Time'].dt.year.max()}")

    st.subheader("Primele Ã®nregistrÄƒri")
    st.dataframe(filtered_df.head(10), use_container_width=True)

    st.subheader("InformaÈ›ii despre tipurile de date")
    data_types = pd.DataFrame({
        'ColoanÄƒ': filtered_df.dtypes.index,
        'Tip': filtered_df.dtypes.values,
        'Valori Nule': filtered_df.isna().sum().values,
        'Procent Nule': (filtered_df.isna().sum().values / len(filtered_df) * 100).round(2)
    })
    data_types['Tip'] = data_types['Tip'].astype(str)
    st.dataframe(data_types, hide_index=True)

    st.subheader("Statistici de bazÄƒ")
    stats_df = filtered_df.describe().round(2).astype(str)
    st.dataframe(stats_df, hide_index=True)

elif menu == "Tratarea Valorilor LipsÄƒ":
    st.header("ğŸ§© Tratarea Valorilor LipsÄƒ")

    na_cols = filtered_df.columns[filtered_df.isna().any()].tolist()

    if not na_cols:
        st.info("Nu existÄƒ valori lipsÄƒ Ã®n datele filtrate!")
    else:
        selected_col = st.selectbox("SelecteazÄƒ coloana pentru tratarea valorilor lipsÄƒ", na_cols)

        st.subheader(f"Vizualizarea valorilor lipsÄƒ pentru coloana {selected_col}")

        col1, col2 = st.columns(2)
        with col1:
            st.metric("Total valori lipsÄƒ", filtered_df[selected_col].isna().sum())
            st.metric("Procent valori lipsÄƒ",
                      f"{(filtered_df[selected_col].isna().sum() / len(filtered_df) * 100):.2f}%")

        with col2:
            if pd.api.types.is_numeric_dtype(filtered_df[selected_col]):
                fig, ax = plt.subplots(figsize=(6, 3))
                filtered_df[selected_col].hist(ax=ax)
                st.pyplot(fig)

        st.subheader("Metode de tratare a valorilor lipsÄƒ")

        tabs = st.tabs(
            ["Metoda 1: Ãnlocuire cu media/mediana/mod", "Metoda 2: Ãnlocuire cu KNN", "Metoda 3: Interpolare"])

        with tabs[0]:
            st.markdown("#### Ãnlocuire cu statistici")

            if pd.api.types.is_numeric_dtype(filtered_df[selected_col]):
                method = st.radio("Alege metoda de Ã®nlocuire:", ["Media", "Mediana"])

                if method == "Media":
                    replace_value = filtered_df[selected_col].mean()
                    df_replaced = filtered_df.copy()
                    df_replaced[selected_col] = df_replaced[selected_col].fillna(replace_value)

                    st.success(f"Valorile lipsÄƒ au fost Ã®nlocuite cu media: {replace_value:.2f}")

                elif method == "Mediana":
                    replace_value = filtered_df[selected_col].median()
                    df_replaced = filtered_df.copy()
                    df_replaced[selected_col] = df_replaced[selected_col].fillna(replace_value)

                    st.success(f"Valorile lipsÄƒ au fost Ã®nlocuite cu mediana: {replace_value:.2f}")

                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("##### Ãnainte de Ã®nlocuire")
                    st.dataframe(filtered_df[[selected_col]].describe(), use_container_width=True)

                with col2:
                    st.markdown("##### DupÄƒ Ã®nlocuire")
                    st.dataframe(df_replaced[[selected_col]].describe(), use_container_width=True)

            else:
                mode_value = filtered_df[selected_col].mode()[0]
                df_replaced = filtered_df.copy()
                df_replaced[selected_col] = df_replaced[selected_col].fillna(mode_value)

                st.success(f"Pentru coloana categoricÄƒ, valorile lipsÄƒ au fost Ã®nlocuite cu modul: {mode_value}")

        with tabs[1]:
            st.markdown("#### Ãnlocuire cu KNN")

            if pd.api.types.is_numeric_dtype(filtered_df[selected_col]):
                k_neighbors = st.slider("NumÄƒr de vecini (K)", 1, 10, 5)

                numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()

                # SelectÄƒm doar cÃ¢teva coloane numerice pentru demonstraÈ›ie
                cols_for_imputation = st.multiselect(
                    "SelecteazÄƒ coloanele pentru imputare (se recomandÄƒ coloane corelate)",
                    numeric_cols,
                    default=[selected_col] + [c for c in numeric_cols if c != selected_col][:2]
                )

                if len(cols_for_imputation) > 1:
                    imputer = KNNImputer(n_neighbors=k_neighbors)

                    # Extragem doar coloanele relevante È™i eliminÄƒm rÃ¢ndurile unde toate valorile sunt NA
                    subset_df = filtered_df[cols_for_imputation].copy()
                    subset_df = subset_df.dropna(how='all')

                    # AplicÄƒm imputarea
                    imputed_array = imputer.fit_transform(subset_df)
                    imputed_df = pd.DataFrame(imputed_array, columns=cols_for_imputation)

                    st.success(f"Valorile lipsÄƒ au fost Ã®nlocuite folosind metoda KNN cu {k_neighbors} vecini")

                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("##### Ãnainte de Ã®nlocuire")
                        st.dataframe(filtered_df[selected_col].describe(), use_container_width=True)

                    with col2:
                        st.markdown("##### DupÄƒ Ã®nlocuire")
                        st.dataframe(imputed_df[selected_col].describe(), use_container_width=True)
                else:
                    st.warning("SelectaÈ›i cel puÈ›in 2 coloane pentru imputare KNN")
            else:
                st.warning("Metoda KNN este aplicabilÄƒ doar pentru coloane numerice")

        with tabs[2]:
            st.markdown("#### Interpolare")

            if pd.api.types.is_numeric_dtype(filtered_df[selected_col]):
                method = st.radio("Metoda de interpolare:", ["Linear", "Polynomial", "Spline"])

                df_interpolated = filtered_df.copy()

                if method == "Linear":
                    df_interpolated[selected_col] = df_interpolated[selected_col].interpolate(method='linear')
                    st.success("Interpolare liniarÄƒ aplicatÄƒ")

                elif method == "Polynomial":
                    df_interpolated[selected_col] = df_interpolated[selected_col].interpolate(method='polynomial',
                                                                                              order=2)
                    st.success("Interpolare polinomialÄƒ de gradul 2 aplicatÄƒ")

                elif method == "Spline":
                    df_interpolated[selected_col] = df_interpolated[selected_col].interpolate(method='spline', order=3)
                    st.success("Interpolare spline cubicÄƒ aplicatÄƒ")

                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("##### Ãnainte de interpolare")
                    st.dataframe(filtered_df[[selected_col]].head(20), use_container_width=True)

                with col2:
                    st.markdown("##### DupÄƒ interpolare")
                    st.dataframe(df_interpolated[[selected_col]].head(20), use_container_width=True)

                st.markdown("##### ComparaÈ›ie statistici")
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("Ãnainte")
                    st.dataframe(filtered_df[selected_col].describe(), use_container_width=True)

                with col2:
                    st.markdown("DupÄƒ")
                    st.dataframe(df_interpolated[selected_col].describe(), use_container_width=True)
            else:
                st.warning("Interpolarea este aplicabilÄƒ doar pentru coloane numerice")

elif menu == "Identificarea Valorilor Extreme":
    st.header("ğŸ” Identificarea È™i Tratarea Valorilor Extreme")

    numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()

    col_for_outlier = st.selectbox("SelecteazÄƒ coloana pentru analiza outlierilor", numeric_cols)

    st.subheader(f"AnalizÄƒ outlieri pentru {col_for_outlier}")

    col1, col2 = st.columns([1, 2])

    with col1:
        st.markdown("### Statistici")
        # CalculeazÄƒ outlieri folosind IQR
        Q1 = filtered_df[col_for_outlier].quantile(0.25)
        Q3 = filtered_df[col_for_outlier].quantile(0.75)
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        outliers = \
        filtered_df[(filtered_df[col_for_outlier] < lower_bound) | (filtered_df[col_for_outlier] > upper_bound)][
            col_for_outlier]

        st.metric("NumÄƒr de outlieri", outliers.count())
        st.metric("Procent outlieri", f"{(outliers.count() / filtered_df[col_for_outlier].count() * 100):.2f}%")
        st.metric("Limita inferioarÄƒ", f"{lower_bound:.2f}")
        st.metric("Limita superioarÄƒ", f"{upper_bound:.2f}")

        if outliers.count() > 0:
            st.metric("Minim outlieri", f"{outliers.min():.2f}")
            st.metric("Maxim outlieri", f"{outliers.max():.2f}")

    with col2:
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.boxplot(x=filtered_df[col_for_outlier], ax=ax)
        ax.set_title(f"Boxplot pentru {col_for_outlier}")
        st.pyplot(fig)

        # HistogramÄƒ cu distribuÈ›ie
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.histplot(filtered_df[col_for_outlier], kde=True, ax=ax)
        ax.axvline(lower_bound, color='r', linestyle='--')
        ax.axvline(upper_bound, color='r', linestyle='--')
        ax.set_title(f"HistogramÄƒ cu limite outlieri pentru {col_for_outlier}")
        st.pyplot(fig)

    st.subheader("Metode de tratare a outlierilor")

    outlier_method = st.radio(
        "SelecteazÄƒ metoda de tratare:",
        ["Vizualizare fÄƒrÄƒ tratare", "Ãnlocuire cu limite", "Transformare logaritmicÄƒ", "Ãnlocuire cu valori calculate"]
    )

    if outlier_method == "Vizualizare fÄƒrÄƒ tratare":
        st.dataframe(filtered_df[[col_for_outlier]].describe(), use_container_width=True)

        # PrezintÄƒ top 10 valori extreme
        if outliers.count() > 0:
            st.subheader("Top 10 valori extreme")
            extreme_values = outliers.sort_values(ascending=False).head(10)
            st.dataframe(pd.DataFrame(extreme_values), use_container_width=True)

    elif outlier_method == "Ãnlocuire cu limite":
        df_capped = filtered_df.copy()

        df_capped[col_for_outlier] = df_capped[col_for_outlier].clip(lower=lower_bound, upper=upper_bound)

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### Ãnainte de tratare")
            st.dataframe(filtered_df[col_for_outlier].describe(), use_container_width=True)

            fig, ax = plt.subplots(figsize=(8, 4))
            sns.boxplot(x=filtered_df[col_for_outlier], ax=ax)
            st.pyplot(fig)

        with col2:
            st.markdown("##### DupÄƒ Ã®nlocuire cu limite")
            st.dataframe(df_capped[col_for_outlier].describe(), use_container_width=True)

            fig, ax = plt.subplots(figsize=(8, 4))
            sns.boxplot(x=df_capped[col_for_outlier], ax=ax)
            st.pyplot(fig)

    elif outlier_method == "Transformare logaritmicÄƒ":
        if (filtered_df[col_for_outlier] <= 0).any():
            st.warning(
                "Transformarea logaritmicÄƒ necesitÄƒ valori pozitive. AdÄƒugÄƒm o constantÄƒ pentru a face toate valorile pozitive.")
            min_val = filtered_df[col_for_outlier].min()
            constant = abs(min_val) + 1 if min_val <= 0 else 0

            df_log = filtered_df.copy()
            df_log[col_for_outlier] = np.log(df_log[col_for_outlier] + constant)

            st.success(
                f"Am adÄƒugat constanta {constant} pentru a face toate valorile pozitive Ã®nainte de transformarea log")
        else:
            df_log = filtered_df.copy()
            df_log[col_for_outlier] = np.log(df_log[col_for_outlier])

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### DistribuÈ›ia originalÄƒ")
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.histplot(filtered_df[col_for_outlier], kde=True, ax=ax)
            st.pyplot(fig)

        with col2:
            st.markdown("##### DistribuÈ›ia dupÄƒ transformarea log")
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.histplot(df_log[col_for_outlier], kde=True, ax=ax)
            st.pyplot(fig)

        st.dataframe(df_log[col_for_outlier].describe(), use_container_width=True)

    elif outlier_method == "Ãnlocuire cu valori calculate":
        replace_method = st.radio(
            "MetodÄƒ de Ã®nlocuire:",
            ["Medie", "MedianÄƒ", "Calcul bazat pe percentile"]
        )

        df_replaced = filtered_df.copy()

        if replace_method == "Medie":
            # Excludem outlieri din calculul mediei
            mean_no_outliers = filtered_df[(filtered_df[col_for_outlier] >= lower_bound) &
                                           (filtered_df[col_for_outlier] <= upper_bound)][col_for_outlier].mean()

            # Ãnlocuim doar outlieri
            df_replaced.loc[(df_replaced[col_for_outlier] < lower_bound), col_for_outlier] = mean_no_outliers
            df_replaced.loc[(df_replaced[col_for_outlier] > upper_bound), col_for_outlier] = mean_no_outliers

            st.success(f"Outlieri Ã®nlocuiÈ›i cu media fÄƒrÄƒ outlieri: {mean_no_outliers:.2f}")

        elif replace_method == "MedianÄƒ":
            median = filtered_df[col_for_outlier].median()

            df_replaced.loc[(df_replaced[col_for_outlier] < lower_bound), col_for_outlier] = median
            df_replaced.loc[(df_replaced[col_for_outlier] > upper_bound), col_for_outlier] = median

            st.success(f"Outlieri Ã®nlocuiÈ›i cu mediana: {median:.2f}")

        elif replace_method == "Calcul bazat pe percentile":
            p10 = filtered_df[col_for_outlier].quantile(0.10)
            p90 = filtered_df[col_for_outlier].quantile(0.90)

            df_replaced.loc[(df_replaced[col_for_outlier] < lower_bound), col_for_outlier] = p10
            df_replaced.loc[(df_replaced[col_for_outlier] > upper_bound), col_for_outlier] = p90

            st.success(f"Outlieri mici Ã®nlocuiÈ›i cu percentila 10: {p10:.2f}")
            st.success(f"Outlieri mari Ã®nlocuiÈ›i cu percentila 90: {p90:.2f}")

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### Boxplot Ã®nainte de Ã®nlocuire")
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.boxplot(x=filtered_df[col_for_outlier], ax=ax)
            st.pyplot(fig)

        with col2:
            st.markdown("##### Boxplot dupÄƒ Ã®nlocuire")
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.boxplot(x=df_replaced[col_for_outlier], ax=ax)
            st.pyplot(fig)

        st.subheader("ComparaÈ›ie statistici")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### Ãnainte")
            st.dataframe(filtered_df[col_for_outlier].describe(), use_container_width=True)

        with col2:
            st.markdown("##### DupÄƒ")
            st.dataframe(df_replaced[col_for_outlier].describe(), use_container_width=True)

elif menu == "GrupÄƒri È™i CorelaÈ›ii":
    st.header("ğŸ“Š GrupÄƒri È™i CorelaÈ›ii")

    tabs = st.tabs(["CorelaÈ›ii", "GrupÄƒri", "FuncÈ›ii Agregate"])

    with tabs[0]:
        st.subheader("Matricea de corelaÈ›ie")

        numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()
        selected_cols = st.multiselect(
            "SelecteazÄƒ coloanele pentru analiza corelaÈ›iilor",
            numeric_cols,
            default=numeric_cols[:8]  # Primele 8 coloane numerice
        )

        if not selected_cols:
            st.warning("SelectaÈ›i cel puÈ›in o coloanÄƒ!")
        else:
            corr_method = st.radio("Metoda de corelaÈ›ie:", ["Pearson", "Spearman", "Kendall"])

            fig, ax = plt.subplots(figsize=(12, 10))
            corr_matrix = filtered_df[selected_cols].corr(method=corr_method.lower())

            mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
            sns.heatmap(corr_matrix, mask=mask, annot=True, fmt=".2f",
                        cmap="coolwarm", ax=ax, cbar_kws={"shrink": .8})

            plt.title(f"Matrice de corelaÈ›ie folosind metoda {corr_method}")
            plt.tight_layout()
            st.pyplot(fig)

            st.subheader("SelecteazÄƒ perechi de coloane pentru analizÄƒ")

            col1, col2 = st.columns(2)
            with col1:
                x_col = st.selectbox("Coloana X", selected_cols, index=0)
            with col2:
                y_col = st.selectbox("Coloana Y", [c for c in selected_cols if c != x_col], index=0)

            fig, ax = plt.subplots(figsize=(10, 6))
            sns.regplot(x=filtered_df[x_col], y=filtered_df[y_col], ax=ax)
            plt.title(f"RelaÈ›ia dintre {x_col} È™i {y_col}")
            plt.tight_layout()
            st.pyplot(fig)

            st.metric(f"Coeficient de corelaÈ›ie {corr_method}",
                      f"{filtered_df[x_col].corr(filtered_df[y_col], method=corr_method.lower()):.3f}")

    with tabs[1]:
        st.subheader("Gruparea datelor")

        # Coloane pentru grupare
        all_cols = filtered_df.columns.tolist()
        categorical_cols = filtered_df.select_dtypes(include=['object', 'category']).columns.tolist()
        date_cols = ['Start_Time']

        # AdÄƒugÄƒm coloane derivate pentru grupare temporalÄƒ
        filtered_df['Month'] = filtered_df['Start_Time'].dt.month
        filtered_df['DayOfWeek'] = filtered_df['Start_Time'].dt.dayofweek
        filtered_df['Hour'] = filtered_df['Start_Time'].dt.hour

        group_by_options = categorical_cols + ['Month', 'DayOfWeek', 'Hour', 'Severity']

        col1, col2 = st.columns(2)
        with col1:
            groupby_col = st.selectbox("GrupeazÄƒ dupÄƒ", group_by_options)

        with col2:
            agg_col = st.selectbox("AplicÄƒ funcÈ›ie pe coloana",
                                   [c for c in filtered_df.select_dtypes(include=[np.number]).columns if
                                    c != groupby_col])

        agg_func = st.radio("FuncÈ›ie de agregare", ["NumÄƒr", "Medie", "SumÄƒ", "Minim", "Maxim", "MedianÄƒ"])

        if agg_func == "NumÄƒr":
            result_df = filtered_df.groupby(groupby_col).size().reset_index(name='NumÄƒr')
        elif agg_func == "Medie":
            result_df = filtered_df.groupby(groupby_col)[agg_col].mean().reset_index(name=f'Medie {agg_col}')
        elif agg_func == "SumÄƒ":
            result_df = filtered_df.groupby(groupby_col)[agg_col].sum().reset_index(name=f'SumÄƒ {agg_col}')
        elif agg_func == "Minim":
            result_df = filtered_df.groupby(groupby_col)[agg_col].min().reset_index(name=f'Minim {agg_col}')
        elif agg_func == "Maxim":
            result_df = filtered_df.groupby(groupby_col)[agg_col].max().reset_index(name=f'Maxim {agg_col}')
        elif agg_func == "MedianÄƒ":
            result_df = filtered_df.groupby(groupby_col)[agg_col].median().reset_index(name=f'MedianÄƒ {agg_col}')

        # SortÄƒm rezultatul
        if agg_func == "NumÄƒr":
            result_df = result_df.sort_values(by='NumÄƒr', ascending=False)
        else:
            result_df = result_df.sort_values(by=result_df.columns[1], ascending=False)

        st.subheader("Rezultat grupare")
        st.dataframe(result_df, use_container_width=True)

        # VizualizÄƒm rezultatul cu un grafic
        fig = px.bar(
            result_df.head(20),
            x=groupby_col,
            y=result_df.columns[1],
            title=f"{agg_func} de {agg_col if agg_func != 'NumÄƒr' else 'accidente'} grupat dupÄƒ {groupby_col}"
        )
        fig.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig, use_container_width=True)

    with tabs[2]:
        st.subheader("FuncÈ›ii de agregare multiple")

        all_cols = filtered_df.columns.tolist()
        categorical_cols = filtered_df.select_dtypes(include=['object', 'category']).columns.tolist()
        numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()

        col1, col2 = st.columns(2)
        with col1:
            groupby_cols = st.multiselect("GrupeazÄƒ dupÄƒ (selecteazÄƒ una sau mai multe coloane)",
                                          categorical_cols + ['Month', 'DayOfWeek', 'Hour', 'Severity'],
                                          default=[categorical_cols[0] if categorical_cols else 'Severity'])

        with col2:
            agg_cols = st.multiselect("Coloane pentru agregare",
                                      [c for c in numeric_cols if c not in groupby_cols],
                                      default=[numeric_cols[0] if numeric_cols else 'Duration'])

        agg_funcs = st.multiselect("FuncÈ›ii de agregare",
                                   ["count", "mean", "sum", "min", "max", "median", "std", "var"],
                                   default=["count", "mean"])

        if not groupby_cols:
            st.warning("SelectaÈ›i cel puÈ›in o coloanÄƒ pentru grupare!")
        elif not agg_cols:
            st.warning("SelectaÈ›i cel puÈ›in o coloanÄƒ pentru agregare!")
        elif not agg_funcs:
            st.warning("SelectaÈ›i cel puÈ›in o funcÈ›ie de agregare!")
        else:
            # Construim dicÈ›ionarul pentru agregare
            agg_dict = {col: agg_funcs for col in agg_cols}

            result_df = filtered_df.groupby(groupby_cols).agg(agg_dict)

            # ResetÄƒm index-ul pentru afiÈ™are mai uÈ™oarÄƒ
            result_df = result_df.reset_index()

            # AfiÈ™Äƒm rezultatul
            st.dataframe(result_df, use_container_width=True)

            # OpÈ›iune pentru descÄƒrcare
            csv = result_df.to_csv(index=False)
            st.download_button(
                label="DescarcÄƒ rezultatele Ã®n CSV",
                data=csv,
                file_name=f"grupare_{'_'.join(groupby_cols)}.csv",
                mime="text/csv"
            )

            # Vizualizare graficÄƒ pentru prima funcÈ›ie de agregare È™i prima coloanÄƒ
            if len(groupby_cols) == 1 and len(result_df) <= 25:
                agg_col_name = f"{agg_cols[0]}_{agg_funcs[0]}"

                fig = px.bar(
                    result_df.head(25),
                    x=groupby_cols[0],
                    y=agg_col_name,
                    title=f"{agg_funcs[0]} de {agg_cols[0]} grupat dupÄƒ {groupby_cols[0]}"
                )
                fig.update_layout(xaxis_tickangle=-45)
                st.plotly_chart(fig, use_container_width=True)

elif menu == "Scalarea Datelor":
    # AplicÄƒm funcÈ›ia pentru vizualizarea È™i aplicarea metodelor de scalare
    st.header("ğŸ”„ Metode de Scalare a Datelor")
    adauga_sectiune_scalare(filtered_df, sidebar=False)

# AdÄƒugÄƒm o nouÄƒ opÈ›iune pentru BoxPlot interactiv
st.sidebar.markdown("---")
if st.sidebar.checkbox("ActiveazÄƒ BoxPlot Interactiv"):
    st.header("ğŸ“Š BoxPlot Interactiv")

    numeric_columns = filtered_df.select_dtypes(include=[np.number]).columns.tolist()
    selected_column = st.selectbox("SelecteazÄƒ coloana pentru BoxPlot", numeric_columns)

    col1, col2 = st.columns([2, 1])

    with col1:
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.boxplot(y=filtered_df[selected_column], ax=ax)
        ax.set_title(f"BoxPlot pentru {selected_column}")
        st.pyplot(fig)

    with col2:
        st.markdown("### Statistici")
        stats = filtered_df[selected_column].describe()

        # CalculÄƒm manual IQR pentru limite de outlieri
        Q1 = stats["25%"]
        Q3 = stats["75%"]
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        outliers_count = filtered_df[(filtered_df[selected_column] < lower_bound) |
                                     (filtered_df[selected_column] > upper_bound)].shape[0]

        st.metric("Minim", f"{stats['min']:.2f}")
        st.metric("Q1 (25%)", f"{Q1:.2f}")
        st.metric("MedianÄƒ", f"{stats['50%']:.2f}")
        st.metric("Q3 (75%)", f"{Q3:.2f}")
        st.metric("Maxim", f"{stats['max']:.2f}")
        st.metric("IQR", f"{IQR:.2f}")
        st.metric("Limita inferioarÄƒ", f"{lower_bound:.2f}")
        st.metric("Limita superioarÄƒ", f"{upper_bound:.2f}")
        st.metric("NumÄƒr outlieri", f"{outliers_count} ({outliers_count / len(filtered_df) * 100:.1f}%)")

    if st.checkbox("AratÄƒ histograma"):
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.histplot(filtered_df[selected_column], kde=True, ax=ax)
        plt.axvline(lower_bound, color='r', linestyle='--', label='Limite outlieri')
        plt.axvline(upper_bound, color='r', linestyle='--')
        plt.legend()
        st.pyplot(fig)

elif menu == "Codificare È™i Regresie":
    st.header("ğŸ”¢ Codificare È™i AnalizÄƒ de Regresie")
    
    tabs = st.tabs(["Codificare Date", "Regresie LogisticÄƒ", "Regresie MultiplÄƒ"])
    
    with tabs[0]:
        st.subheader("Codificare Date")
        
        # SelectÄƒm coloanele categorice pentru codificare
        categorical_cols = filtered_df.select_dtypes(include=['object']).columns.tolist()
        selected_col = st.selectbox("SelecteazÄƒ coloana pentru codificare", categorical_cols)
        
        encoding_method = st.radio("Alege metoda de codificare:", ["Label Encoding", "One-Hot Encoding"])
        
        if encoding_method == "Label Encoding":
            le = LabelEncoder()
            encoded_values = le.fit_transform(filtered_df[selected_col].fillna('Missing'))
            
            # CreÄƒm un DataFrame pentru vizualizare
            encoding_df = pd.DataFrame({
                'Valoare OriginalÄƒ': filtered_df[selected_col].fillna('Missing'),
                'Valoare CodificatÄƒ': encoded_values
            }).drop_duplicates().sort_values('Valoare CodificatÄƒ')
            
            st.dataframe(encoding_df, use_container_width=True)
            
        else:  # One-Hot Encoding
            ohe = OneHotEncoder(sparse=False)
            encoded_values = ohe.fit_transform(filtered_df[[selected_col]].fillna('Missing'))
            
            # CreÄƒm un DataFrame pentru vizualizare
            feature_names = [f"{selected_col}_{val}" for val in ohe.categories_[0]]
            encoding_df = pd.DataFrame(encoded_values, columns=feature_names)
            
            st.dataframe(encoding_df.head(), use_container_width=True)
            
            # VizualizÄƒm distribuÈ›ia valorilor codificate
            fig = px.bar(encoding_df.sum(), title=f"DistribuÈ›ia valorilor codificate pentru {selected_col}")
            st.plotly_chart(fig)
    
    with tabs[1]:
        st.subheader("Regresie LogisticÄƒ")
        
        # SelectÄƒm variabilele pentru regresie logisticÄƒ
        target_col = st.selectbox("SelecteazÄƒ variabila È›intÄƒ (binarÄƒ)", 
                                ['Severity', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit'],
                                key="logistic_target")
        
        feature_cols = st.multiselect("SelecteazÄƒ variabilele predictoare (numerice)",
                                    filtered_df.select_dtypes(include=[np.number]).columns.tolist(),
                                    default=['Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)'],
                                    key="logistic_features")
        
        if len(feature_cols) > 0:
            # PregÄƒtim datele
            X = filtered_df[feature_cols].fillna(filtered_df[feature_cols].mean())
            y = (filtered_df[target_col] > filtered_df[target_col].median()).astype(int)
            
            # ÃmpÄƒrÈ›im datele Ã®n set de antrenare È™i test
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            # AntrenÄƒm modelul
            model = LogisticRegression(max_iter=1000)
            model.fit(X_train, y_train)
            
            # EvaluÄƒm modelul
            y_pred = model.predict(X_test)
            
            st.subheader("Rezultate Model")
            st.text(classification_report(y_test, y_pred))
            
            # VizualizÄƒm matricea de confuzie
            cm = confusion_matrix(y_test, y_pred)
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
            ax.set_xlabel('Predicted')
            ax.set_ylabel('Actual')
            st.pyplot(fig)
            
            # AfiÈ™Äƒm coeficienÈ›ii modelului
            coef_df = pd.DataFrame({
                'Feature': feature_cols,
                'Coefficient': model.coef_[0]
            })
            st.dataframe(coef_df.sort_values('Coefficient', ascending=False), use_container_width=True)
    
    with tabs[2]:
        st.subheader("Regresie MultiplÄƒ")
        
        # SelectÄƒm variabilele pentru regresie multiplÄƒ
        target_col = st.selectbox("SelecteazÄƒ variabila È›intÄƒ (numericÄƒ)", 
                                ['Duration', 'Distance(mi)', 'Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)'],
                                key="multiple_target")
        
        feature_cols = st.multiselect("SelecteazÄƒ variabilele predictoare (numerice)",
                                    filtered_df.select_dtypes(include=[np.number]).columns.tolist(),
                                    default=['Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)'],
                                    key="multiple_features")
        
        if len(feature_cols) > 0:
            # PregÄƒtim datele
            X = filtered_df[feature_cols].fillna(filtered_df[feature_cols].mean())
            y = filtered_df[target_col].fillna(filtered_df[target_col].mean())
            
            # AdÄƒugÄƒm constanta pentru statsmodels
            X = sm.add_constant(X)
            
            # AntrenÄƒm modelul
            model = sm.OLS(y, X).fit()
            
            # AfiÈ™Äƒm rezultatele
            st.subheader("Rezultate Model")
            st.text(model.summary())
            
            # VizualizÄƒm reziduurile
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.scatter(model.fittedvalues, model.resid)
            ax.axhline(y=0, color='r', linestyle='--')
            ax.set_xlabel('Valori Prezise')
            ax.set_ylabel('Reziduuri')
            st.pyplot(fig)
            
            # VizualizÄƒm coeficienÈ›ii
            coef_df = pd.DataFrame({
                'Feature': ['const'] + feature_cols,
                'Coefficient': model.params,
                'P-value': model.pvalues
            })
            st.dataframe(coef_df.sort_values('P-value'), use_container_width=True)

elif menu == "Clusterizare":
    st.header("ğŸ” Analiza ClusterizÄƒrii")
    
    # SelectÄƒm variabilele pentru clusterizare
    numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()
    feature_cols = st.multiselect(
        "SelecteazÄƒ variabilele pentru clusterizare",
        numeric_cols,
        default=['Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)'],
        key="cluster_features"
    )
    
    if len(feature_cols) > 1:
        # PregÄƒtim datele
        X = filtered_df[feature_cols].fillna(filtered_df[feature_cols].mean())
        
        # ScalÄƒm datele
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # DeterminÄƒm numÄƒrul optim de clustere
        max_clusters = min(10, len(filtered_df) - 1)
        
        # CalculÄƒm metricile pentru diferite numere de clustere
        silhouette_scores = []
        inertia_scores = []
        calinski_scores = []
        
        for n_clusters in range(2, max_clusters + 1):
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            clusters = kmeans.fit_predict(X_scaled)
            
            # CalculÄƒm scorurile
            silhouette_scores.append(silhouette_score(X_scaled, clusters))
            inertia_scores.append(kmeans.inertia_)
            calinski_scores.append(calinski_harabasz_score(X_scaled, clusters))
        
        # CreÄƒm un DataFrame cu rezultatele
        results_df = pd.DataFrame({
            'NumÄƒr Clustere': range(2, max_clusters + 1),
            'Scor SiluetÄƒ': silhouette_scores,
            'InerÈ›ie': inertia_scores,
            'Scor Calinski-Harabasz': calinski_scores
        })
        
        # AfiÈ™Äƒm rezultatele
        st.subheader("Determinarea numÄƒrului optim de clustere")
        
        # CreÄƒm un tab pentru fiecare metodÄƒ
        tabs = st.tabs(["Scor SiluetÄƒ", "Metoda Cotului", "Calinski-Harabasz"])
        
        with tabs[0]:
            st.write("Scorul de siluetÄƒ mÄƒsoarÄƒ cÃ¢t de bine sunt separate clusterele. Valori mai mari indicÄƒ o clusterizare mai bunÄƒ.")
            fig = go.Figure()
            
            # AdÄƒugÄƒm inerÈ›ia
            fig.add_trace(go.Scatter(
                x=results_df['NumÄƒr Clustere'],
                y=results_df['Scor SiluetÄƒ'],
                name='Scor SiluetÄƒ',
                line=dict(color='blue')
            ))
            
            # ConfigurÄƒm layout-ul
            fig.update_layout(
                title='Scor SiluetÄƒ vs NumÄƒr Clustere',
                xaxis_title='NumÄƒr Clustere',
                yaxis_title='Scor SiluetÄƒ'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # GÄƒsim numÄƒrul optim de clustere bazat pe scorul de siluetÄƒ
            optimal_silhouette = results_df.loc[results_df['Scor SiluetÄƒ'].idxmax()]
            st.success(f"NumÄƒrul optim de clustere bazat pe scorul de siluetÄƒ: {int(optimal_silhouette['NumÄƒr Clustere'])}")
        
        with tabs[1]:
            st.write("Metoda cotului (elbow method) analizeazÄƒ rata de scÄƒdere a inerÈ›iei. CÄƒutÄƒm 'cotul' Ã®n grafic.")
            
            # CalculÄƒm rata de scÄƒdere a inerÈ›iei
            results_df['Rata ScÄƒdere'] = results_df['InerÈ›ie'].pct_change()
            
            # CreÄƒm figura cu douÄƒ axe y
            fig = go.Figure()
            
            # AdÄƒugÄƒm inerÈ›ia
            fig.add_trace(go.Scatter(
                x=results_df['NumÄƒr Clustere'],
                y=results_df['InerÈ›ie'],
                name='InerÈ›ie',
                line=dict(color='blue')
            ))
            
            # AdÄƒugÄƒm rata de scÄƒdere
            fig.add_trace(go.Scatter(
                x=results_df['NumÄƒr Clustere'],
                y=results_df['Rata ScÄƒdere'],
                name='Rata ScÄƒdere',
                line=dict(color='red'),
                yaxis='y2'
            ))
            
            # ConfigurÄƒm layout-ul
            fig.update_layout(
                title='Metoda Cotului (Elbow Method)',
                xaxis_title='NumÄƒr Clustere',
                yaxis=dict(
                    title=dict(
                        text='InerÈ›ie',
                        font=dict(color='blue')
                    ),
                    tickfont=dict(color='blue')
                ),
                yaxis2=dict(
                    title=dict(
                        text='Rata ScÄƒdere',
                        font=dict(color='red')
                    ),
                    tickfont=dict(color='red'),
                    overlaying='y',
                    side='right'
                )
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # GÄƒsim punctul de cot
            optimal_elbow = results_df.loc[results_df['Rata ScÄƒdere'].idxmin()]
            st.success(f"Sugestie pentru numÄƒrul optim de clustere bazat pe metoda cotului: {int(optimal_elbow['NumÄƒr Clustere'])}")
        
        with tabs[2]:
            st.write("Scorul Calinski-Harabasz mÄƒsoarÄƒ raportul dintre dispersia inter-cluster È™i intra-cluster. Valori mai mari indicÄƒ o clusterizare mai bunÄƒ.")
            fig = go.Figure()
            
            # AdÄƒugÄƒm scorul Calinski-Harabasz
            fig.add_trace(go.Scatter(
                x=results_df['NumÄƒr Clustere'],
                y=results_df['Scor Calinski-Harabasz'],
                name='Scor Calinski-Harabasz',
                line=dict(color='green')
            ))
            
            # ConfigurÄƒm layout-ul
            fig.update_layout(
                title='Scor Calinski-Harabasz vs NumÄƒr Clustere',
                xaxis_title='NumÄƒr Clustere',
                yaxis_title='Scor Calinski-Harabasz'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # GÄƒsim numÄƒrul optim de clustere bazat pe scorul Calinski-Harabasz
            optimal_calinski = results_df.loc[results_df['Scor Calinski-Harabasz'].idxmax()]
            st.success(f"NumÄƒrul optim de clustere bazat pe scorul Calinski-Harabasz: {int(optimal_calinski['NumÄƒr Clustere'])}")
        
        # AplicÄƒm K-means cu numÄƒrul optim de clustere
        n_clusters = int(optimal_silhouette['NumÄƒr Clustere'])
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        clusters = kmeans.fit_predict(X_scaled)
        
        # AfiÈ™Äƒm distribuÈ›ia punctelor Ã®n clustere
        st.subheader("DistribuÈ›ia punctelor Ã®n clustere")
        cluster_distribution = pd.Series(clusters).value_counts().sort_index()
        st.dataframe(cluster_distribution.to_frame('NumÄƒr Puncte'), hide_index=True)
        
        # CalculÄƒm scorul de siluetÄƒ final
        silhouette_avg = silhouette_score(X_scaled, clusters)
        
        # AdÄƒugÄƒm clusterele la DataFrame
        df_clustered = filtered_df.copy()
        df_clustered['Cluster'] = clusters
        
        # AfiÈ™Äƒm statistici despre clustere
        st.subheader("Statistici despre clustere")
        cluster_stats = df_clustered.groupby('Cluster')[feature_cols].mean()
        # Convertim la string pentru a evita probleme de serializare
        cluster_stats_str = cluster_stats.round(2).astype(str)
        st.dataframe(cluster_stats_str, hide_index=True)
        
        # AfiÈ™Äƒm scorul de siluetÄƒ
        st.metric("Scor de siluetÄƒ", f"{silhouette_avg:.3f}")
        
        # VizualizÄƒm clusterele Ã®n spaÈ›iul 2D
        st.subheader("Vizualizare clustere")
        
        # SelectÄƒm douÄƒ variabile pentru vizualizare
        col1, col2 = st.columns(2)
        with col1:
            x_axis = st.selectbox("AxeazÄƒ X", feature_cols, index=0, key="cluster_x")
        with col2:
            y_axis = st.selectbox("AxeazÄƒ Y", feature_cols, index=1, key="cluster_y")
        
        if x_axis == y_axis:
            st.warning("Alege douÄƒ coloane diferite pentru X È™i Y!")
        else:
            # CreÄƒm DataFrame-ul scalat
            df_scaled = pd.DataFrame(X_scaled, columns=feature_cols)
            df_scaled['Cluster'] = clusters
            
            # CreÄƒm figura pentru clustere
            fig = go.Figure()
            
            # Definim o paletÄƒ de culori pentru clustere
            colors = px.colors.qualitative.Set1
            
            # AdÄƒugÄƒm punctele pentru fiecare cluster
            for cluster in range(n_clusters):
                cluster_data = df_scaled[df_scaled['Cluster'] == cluster]
                fig.add_trace(go.Scatter(
                    x=cluster_data[x_axis],
                    y=cluster_data[y_axis],
                    mode='markers',
                    name=f'Cluster {cluster}',
                    marker=dict(
                        size=8,
                        color=colors[cluster % len(colors)]
                    )
                ))
            
            # AdÄƒugÄƒm centroidele
            centroids = kmeans.cluster_centers_
            centroids_df = pd.DataFrame(centroids, columns=feature_cols)
            fig.add_trace(go.Scatter(
                x=centroids_df[x_axis],
                y=centroids_df[y_axis],
                mode='markers',
                name='Centroide',
                marker=dict(
                    size=12,
                    symbol='star',
                    color='black'
                )
            ))
            
            # ConfigurÄƒm layout-ul
            fig.update_layout(
                title=dict(
                    text=f'Clustere Ã®n spaÈ›iul {x_axis} vs {y_axis} (date scalate)',
                    font=dict(size=16)
                ),
                xaxis_title=x_axis,
                yaxis_title=y_axis,
                showlegend=True,
                legend=dict(
                    title='Clustere',
                    yanchor="top",
                    y=0.99,
                    xanchor="left",
                    x=0.01
                )
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # AdÄƒugÄƒm È™i un scatter plot cu datele originale pentru comparaÈ›ie
            fig_original = go.Figure()
            
            # AdÄƒugÄƒm punctele pentru fiecare cluster
            for cluster in range(n_clusters):
                cluster_data = df_clustered[df_clustered['Cluster'] == cluster]
                fig_original.add_trace(go.Scatter(
                    x=cluster_data[x_axis],
                    y=cluster_data[y_axis],
                    mode='markers',
                    name=f'Cluster {cluster}',
                    marker=dict(
                        size=8,
                        color=colors[cluster % len(colors)]
                    )
                ))
            
            # ConfigurÄƒm layout-ul
            fig_original.update_layout(
                title=dict(
                    text=f'Clustere Ã®n spaÈ›iul {x_axis} vs {y_axis} (date originale)',
                    font=dict(size=16)
                ),
                xaxis_title=x_axis,
                yaxis_title=y_axis,
                showlegend=True,
                legend=dict(
                    title='Clustere',
                    yanchor="top",
                    y=0.99,
                    xanchor="left",
                    x=0.01
                )
            )
            
            st.plotly_chart(fig_original, use_container_width=True)
    else:
        st.warning("SelectaÈ›i cel puÈ›in douÄƒ variabile pentru clusterizare!")